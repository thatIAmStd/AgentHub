{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f8f895",
   "metadata": {},
   "source": [
    "### LangGraph 多智能体协作中文指南\n",
    "\n",
    "在单个领域中，通常一个智能体能够有效地使用一些工具，但即使是使用强大的模型（例如 GPT-4），它在使用大量工具时效果可能会有所降低。\n",
    "\n",
    "一种解决复杂任务的方法是采用“分而治之”的方式：为每个任务或领域创建一个专门的智能体，并将任务路由到正确的“专家”。\n",
    "\n",
    "本指南灵感来自 Wu 等人的论文《AutoGen: 通过多智能体对话实现下一代 LLM 应用》 展示了使用 LangGraph 进行多智能体协作的一种方法。\n",
    "\n",
    "### 工作流程概述\n",
    "\n",
    "工作流程清晰地展示了多智能体协作的核心步骤，便于理解 LangGraph 的实现方法。\n",
    "\n",
    "1. **定义辅助函数：create_agent**：为每个任务创建独立的智能体，例如研究智能体、图表生成器智能体等。每个智能体使用独立的语言模型和工具。\n",
    "2. **定义工具**：为每个智能体提供专用的工具，例如 Tavily 搜索工具和 Python REPL 工具，用于执行特定任务。\n",
    "3. **定义辅助函数：agent_node**：将每个智能体与对应任务进行关联，定义图中的智能体节点，使其能够处理特定任务。\n",
    "4. **定义研究智能体及节点: Researcher**: 研究智能体使用 Tavily 搜索工具，回应用户提问。\n",
    "5. **定义图表生成器智能体及节点: Chart_Generator**: 根据提供的数据，在沙盒环境执行 Python 代码生成图表。\n",
    "6. **导入预构建的工具节点: ToolNode**: 将2中定义的 Tavily 搜索工具和 Python REPL 工具作为一个工具节点，这样可以方便地在工作流中使用这些工具。\n",
    "7. **建立智能体节点间通信: AgentState**：通过 LangGraph 实现智能体间通信，智能体能够共享状态并相互协作完成复杂任务。\n",
    "8. **定义工作流（状态图)**：创建状态图以管理多智能体协作的流程，包含任务路由和边逻辑，确保正确的智能体按顺序执行。\n",
    "9. **执行工作流**：根据状态图执行多智能体任务，通过工具调用和智能体协作，完成目标任务并生成最终输出。\n",
    "\n",
    "最终的工作流执行时应像下图所示：\n",
    "\n",
    "![simple_multi_agent_diagram](./images/simple_multi_agent_diagram.png)\n",
    "\n",
    "\n",
    "### **说明**\n",
    "\n",
    "经过多次测试，多智能体在 gpt-4o 上成功运行。见指南最后的 GPT-4o 模型生成结果 章节。\n",
    "\n",
    "当切换为 gpt-4o-mini 时，`Research` 能够生成对应的 Python 代码，但会一定概率路由 `Chart_Generator` 失败，无法调用 Python REPL 工具生成图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain_openai langsmith pandas langchain_experimental matplotlib langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e485f-3a3c-46fe-965d-48ca55de6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# 定义一个帮助函数来检查环境变量，如果不存在则提示用户输入\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"请输入您的 {var}\")\n",
    "\n",
    "# 设置 OpenAI 和 Langchain API 密钥\n",
    "# _set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# _set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# 可选：在 LangSmith 中添加追踪功能\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21546ee0",
   "metadata": {},
   "source": [
    "\n",
    "### 1. 辅助函数：创建智能体\n",
    "\n",
    "以下助手函数将帮助我们创建智能体。这些智能体将成为图中的节点。\n",
    "\n",
    "#### 注释说明：\n",
    "- 该函数 `create_agent` 用于创建一个智能体，通过为该智能体提供系统消息和可以使用的工具来指定其行为。\n",
    "- `ChatPromptTemplate.from_messages` 是用于构建该智能体的对话提示模板，系统消息告诉智能体它是如何与其他智能体协作的。\n",
    "- 提示模板通过 `partial` 函数插入了系统消息和工具名称，使得智能体能够根据提供的工具执行任务。\n",
    "- 最终，智能体被绑定到所提供的 LLM（大型语言模型）和工具列表中，构成一个完整的智能体逻辑。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6530646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "# 创建智能体的函数，绑定 LLM（大型语言模型） 和工具\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"创建一个智能体。\"\"\"\n",
    "    # 定义智能体的提示模板，包含系统消息和工具信息\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),  # 用于替换的消息占位符\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 将系统消息部分和工具名称插入到提示模板中\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    \n",
    "    # 将提示模板与语言模型和工具绑定\n",
    "    return prompt | llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7be88e-c428-46de-8986-5faa7e4e9bda",
   "metadata": {},
   "source": [
    "\n",
    "#### `partial` 是什么\n",
    "\n",
    "在 Python 中，`partial` 方法是 `functools` 模块中的一个功能，它用于创建一个**新的函数**，这个函数是基于原函数的**部分参数已经固定**的版本。这在需要重复调用同一函数，并且传递相同的某些参数时非常有用。\n",
    "\n",
    "####  `partial` 的基本理解\n",
    "\n",
    "通过 `partial`，我们可以预先为函数的某些参数赋值，生成一个新的函数，这个新函数已经预先固定了部分参数，只需要再传递剩下的参数即可。\n",
    "\n",
    "#### `prompt.partial` 解析\n",
    "\n",
    "这里的 `partial` 用于创建一个新的提示模板对象，并为 `system_message` 和 `tool_names` 这两个参数提供了值。这相当于对提示模板的“定制”，预先指定了这些参数的值。\n",
    "\n",
    "**`partial` 的具体作用：**\n",
    "\n",
    "1. 调用 `prompt.partial(system_message=system_message)`，预先为 `system_message` 参数赋值，生成一个新的提示模板，固定了系统消息的内容。\n",
    "2. 调用 `prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))`，为 `tool_names` 参数赋值，将所有工具的名称合并成一个字符串，并固定在新的模板中。\n",
    "\n",
    "通过这两步 `partial` 调用，`prompt` 对象中已经预先填入了 `system_message` 和 `tool_names` 这两个参数，简化了后续的调用过程。\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407bcc6",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 定义工具\n",
    "\n",
    "接下来我们定义一些未来智能体将使用的工具。\n",
    "\n",
    "#### 注释说明：\n",
    "- `tavily_tool`: 定义了一个 Tavily 搜索工具，可以搜索最多 5 条结果。\n",
    "- `repl`: 定义了一个 Python REPL 工具，用于执行 Python 代码块。\n",
    "- `python_repl` 函数：这是一个装饰的工具函数，接受 Python 代码作为输入，并通过 `PythonREPL` 环境执行代码。成功执行后返回执行的代码和输出。如果发生错误，则捕获并返回错误信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e729d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Tavily 搜索工具，用于搜索最多 5 条结果\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Python REPL 工具，用于执行 Python 代码\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a379da6",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "### 3. 辅助函数：智能体节点\n",
    "\n",
    "下面我们定义智能体节点函数（`agent_node`)，然后使用它分别定义2个智能体节点：\n",
    "- Researcher\n",
    "- Chart_Generator\n",
    "\n",
    "#### 注释说明：\n",
    "\n",
    "- `agent_node` 函数是一个辅助函数，用于创建一个智能体节点。它接受当前的 `state`（状态）、`agent`（智能体） 和 `name`（智能体的名称），并返回一个新的状态字典，包含消息和发送者。\n",
    "- `research_agent`: 使用 `create_agent` 函数创建了一个研究智能体，使用 `research_llm` 作为语言模型，并且绑定了 `tavily_tool` 搜索工具。\n",
    "- `chart_agent`: 同样使用 `create_agent` 创建了图表生成器智能体，使用 `chart_llm` 作为语言模型，并绑定了 `python_repl` 代码执行工具。\n",
    "- `functools.partial`: 用于创建特定名称的智能体节点，例如 `\"Researcher\"` 和 `\"Chart_Generator\"`，并与各自的智能体绑定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910d2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 辅助函数：为智能体创建一个节点\n",
    "def agent_node(state, agent, name):\n",
    "    # 调用智能体，获取结果\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    # 将智能体的输出转换为适合追加到全局状态的格式\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass  # 如果是工具消息，跳过处理\n",
    "    else:\n",
    "        # 将结果转换为 AIMessage，并排除部分字段\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    \n",
    "    # 返回更新后的状态，包括消息和发送者\n",
    "    return {\n",
    "        \"messages\": [result],  # 包含新生成的消息\n",
    "        # 我们使用严格的工作流程，通过记录发送者来知道接下来传递给谁\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec876b-9041-4ce1-a7ea-c81fba984bf6",
   "metadata": {},
   "source": [
    "#### 关于 `AIMessage` 构造\n",
    "\n",
    "`AIMessage` 是 LangChain 中用于表示 AI 模型回复的类，它封装了 AI 生成的文本或内容。为了让 Python 初学者更好地理解，我们可以从以下几个方面详细说明 `AIMessage` 的构造方法及其相关概念。\n",
    "\n",
    "##### `AIMessage` 构造方法简介\n",
    "\n",
    "在代码中，`AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)` 这段代码使用了 `AIMessage` 的构造方法。`AIMessage` 的目的是将 AI 生成的消息封装起来，方便后续处理和传递。这里的构造方法通过传递字典参数创建 `AIMessage` 对象。\n",
    "\n",
    "##### `AIMessage` 类的常见构造参数：\n",
    "- **content**: 这是消息的主要部分，通常是 AI 模型生成的文本内容。例如，一个简单的对话模型可能会生成一个包含回答问题的字符串。\n",
    "- **name**: 可选参数，用于标识发送消息的 AI 模型或智能体的名称。在你的代码中，`name=name` 表示为智能体分配一个名称（如 `\"Researcher\"` 或 `\"Chart_Generator\"`），以便在不同智能体之间进行区分。\n",
    "- **additional_metadata**: 有时候，消息不仅仅包含文本内容，还可能附加其他元数据，如调用的工具、时间戳等。\n",
    "\n",
    "##### 深入理解构造方法中的步骤：\n",
    "\n",
    "1. **`result.dict()`**: \n",
    "   这一部分将 `result` 对象转换为字典。字典是一种键值对的结构，便于存储和管理数据。Python 中的 `dict()` 方法会把 `result` 对象的所有属性转换成字典的形式，方便在构造 `AIMessage` 时传递这些数据。\n",
    "\n",
    "2. **`exclude={\"type\", \"name\"}`**:\n",
    "   在构造 `AIMessage` 时，使用了 `exclude` 参数来排除某些不必要的字段。`type` 和 `name` 这两个字段不会被传递给 `AIMessage`，这是因为它们可能不是 AI 消息本身的必要部分或已经在其他地方定义过。\n",
    "\n",
    "3. **`name=name`**:\n",
    "   这里的 `name` 参数表示智能体的名称，它是在 `agent_node` 函数中作为参数传递的。在构造 `AIMessage` 时，通过这个参数来标识消息的来源智能体是谁，比如 `\"Researcher\"` 或 `\"Chart_Generator\"`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33515a5-14bf-4100-a5b7-7625fbf1bc9e",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### 4. 定义 研究智能体及其节点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82030b1d-bf6d-4cc0-8f07-63fea8af9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 Agent 配置各自的大模型\n",
    "research_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "chart_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dfa4ea-1cd1-423a-b24a-865308631d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 研究智能体及其节点\n",
    "research_agent = create_agent(\n",
    "    research_llm,  # 使用 research_llm 作为研究智能体的语言模型\n",
    "    [tavily_tool],  # 研究智能体使用 Tavily 搜索工具\n",
    "    system_message=\"Before using the search engine, carefully think through and clarify the query. \"\n",
    "    \"Then, conduct a single search that addresses all aspects of the query in one go.\",  # 系统消息，指导智能体如何使用搜索工具\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa442a3-c015-4d02-8216-518fd6c3aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 functools.partial 创建研究智能体的节点，指定该节点的名称为 \"Researcher\"\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07df36-d186-45a2-bf96-8da29b39ad56",
   "metadata": {},
   "source": [
    "这里的 `functools.partial` 创建了一个新的函数 `research_node`，该函数基于原始的 `agent_node` 函数，且已经为 `agent_node` 的部分参数（`agent` 和 `name`）预先设置了值。新的 `research_node` 函数只需要接收剩余的参数就可以正常运行。\n",
    "\n",
    "\n",
    "**`partial` 的具体作用：**\n",
    "\n",
    "1. **原始函数 `agent_node`**：\n",
    "   ```python\n",
    "   def agent_node(state, agent, name):\n",
    "       # 函数体...\n",
    "   ```\n",
    "   - `agent_node` 是一个接受 `state`, `agent`, 和 `name` 三个参数的函数。\n",
    "\n",
    "2. **使用 `functools.partial`**：\n",
    "   ```python\n",
    "   research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "   ```\n",
    "   - 通过 `functools.partial`，我们创建了一个新的函数 `research_node`，它仍然是 `agent_node`，但 `agent` 参数和 `name` 参数已经被预先固定：\n",
    "     - `agent=research_agent`\n",
    "     - `name=\"Researcher\"`\n",
    "   - 也就是说，调用 `research_node` 时，只需要传递 `state` 参数，因为 `agent` 和 `name` 已经有默认值了。\n",
    "\n",
    "**举个例子**\n",
    "\n",
    "假设有一个函数 `agent_node`，你经常需要调用它并传递相同的 `agent` 和 `name`，那么每次调用时重复写这些参数会很冗余。使用 `partial` 可以避免这种重复。\n",
    "\n",
    "```python\n",
    "# 原始函数定义\n",
    "def agent_node(state, agent, name):\n",
    "    print(f\"State: {state}, Agent: {agent}, Name: {name}\")\n",
    "\n",
    "# 预先设置 agent 和 name 参数\n",
    "research_node = functools.partial(agent_node, agent=\"research_agent_value\", name=\"Researcher\")\n",
    "\n",
    "# 调用时只需要传递剩下的参数\n",
    "research_node(state=\"current_state\")\n",
    "# 输出: State: current_state, Agent: research_agent_value, Name: Researcher\n",
    "```\n",
    "\n",
    "#### `functools.partial` 的优势\n",
    "\n",
    "1. **减少重复代码**：在你需要多次调用同一个函数并且某些参数不变时，`partial` 可以避免每次都传递相同的参数。\n",
    "   \n",
    "2. **简化函数调用**：在需要频繁使用相同参数时，`partial` 提供了更简洁的写法，使代码更易于维护。\n",
    "\n",
    "#### 总结\n",
    "\n",
    "在这段代码中，`functools.partial` 的用法预先为 `agent_node` 函数的部分参数（`agent` 和 `name`）赋值，创建了一个新函数 `research_node`。调用 `research_node` 时，只需要传递剩下的参数（`state`），从而简化了函数调用的流程。\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149beb7-e216-4630-9b19-d3bc6949f5da",
   "metadata": {},
   "source": [
    "### 5. 定义 图表生成器智能体及其节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51bd833-1b7f-4287-b23d-11eb7f55ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_agent = create_agent(\n",
    "    chart_llm,  # 使用 chart_llm 作为图表生成器智能体的语言模型\n",
    "    [python_repl],  # 图表生成器智能体使用 Python REPL 工具\n",
    "    system_message=\"Create clear and user-friendly charts based on the provided data.\",  # 系统消息，指导智能体如何生成图表\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268da6ad-d4b8-42c8-bb0f-4f41620c6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 functools.partial 创建图表生成器智能体的节点，指定该节点的名称为 \"Chart_Generator\"\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"Chart_Generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6708b47",
   "metadata": {},
   "source": [
    "\n",
    "### 6. 导入预构建的工具节点\n",
    "\n",
    "我们现在导入预构建的工具节点 `ToolNode` （运行上一个AIMessage中调用工具的节点。）。将 Tavily 搜索工具和 Python REPL 工具作为一个工具节点，这样可以方便地在工作流中使用这些工具。\n",
    "\n",
    "### 什么是 ToolNode？\n",
    "\n",
    "**ToolNode** 是 LangChain 的一个预构建节点，它能够从图状态（`graph state`）中提取消息并调用指定的工具，最后将工具调用的结果反馈回图的状态中。ToolNode 非常适合与 LangGraph 中的 ReAct agent 协同工作，但也可以与任何 `StateGraph` 配合使用，只要状态中有 `messages` 键和合适的消息处理方式。\n",
    "\n",
    "#### ToolNode 的特点\n",
    "1. **工具调用**：ToolNode 可以根据状态中的消息自动调用指定的工具，并返回工具的执行结果。\n",
    "2. **兼容性**：可以与任意支持工具调用的 LangChain 模型配合使用。\n",
    "3. **并行工具调用**：支持同时调用多个工具，并处理工具返回的多个结果。\n",
    "4. **错误处理**：ToolNode 默认启用了错误处理，可以处理工具在执行过程中的异常情况。\n",
    "\n",
    "#### 与对话模型结合使用\n",
    "\n",
    "在使用像 Anthropic 这样的对话模型时，模型可以自动生成带有 `tool_calls` 的 `AIMessage`，这样我们可以直接将模型生成的消息传给 ToolNode 来执行工具调用：\n",
    "\n",
    "```python\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "model_with_tools = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").bind_tools(tools)\n",
    "\n",
    "tool_node.invoke({\"messages\": [model_with_tools.invoke(\"what's the weather in sf?\")]})\n",
    "# 返回: {'messages': [ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='toolu_01LFvAVT3xJMeZS6kbWwBGZK')]}\n",
    "```\n",
    "\n",
    "#### ToolNode 与 ReAct Agent 结合\n",
    "\n",
    "ReAct Agent 是 LangGraph 中的一种智能体，它会反复调用工具，直到收集到足够的信息来解决问题。以下是 ReAct Agent 的基本工作流，它通过工具节点来完成工具调用：\n",
    "\n",
    "```python\n",
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 创建状态图\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# 定义两个节点：一个用于调用模型，一个用于调用工具\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(\"__start__\", \"agent\")  # 从 agent 节点开始\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)  # 根据条件判断是否继续调用工具\n",
    "workflow.add_edge(\"tools\", \"agent\")  # 工具调用完成后，返回 agent 节点\n",
    "\n",
    "app = workflow.compile()  # 编译状态图\n",
    "```\n",
    "\n",
    "#### 错误处理\n",
    "\n",
    "ToolNode 默认启用了错误处理，可以处理工具执行中的异常情况。如果想禁用错误处理，可以设置 `handle_tool_errors=False`。\n",
    "\n",
    "#### 总结\n",
    "\n",
    "**ToolNode** 是一个非常强大的组件，它能够自动调用工具并将结果反馈回工作流。它可以处理单个或多个工具调用，并与 LangChain 模型紧密结合，使得在复杂的多步骤任务中能够更高效地调用外部 API 或工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034f427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 定义工具列表，包括 Tavily 搜索工具和 Python REPL 工具\n",
    "tools = [tavily_tool, python_repl]\n",
    "\n",
    "# 创建工具节点，负责工具的调用\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f3686-eda1-4c68-913c-e5f8cf9f1ea1",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32b59a-dae0-4b42-8b44-991c6ca18dfd",
   "metadata": {},
   "source": [
    "\n",
    "### 7. 建立智能体节点间通信 AgentState\n",
    "\n",
    "定义智能体节点和工具节点后，接下来需要在 Graph 中使它们互相通信。\n",
    "\n",
    "因此，我们需要定义节点间的消息传递数据结构：AgentState\n",
    "\n",
    "我们使用一个消息列表，并包含一个键来跟踪最近的发送者。\n",
    "\n",
    "#### 注释说明：\n",
    "- `AgentState` 是一个 `TypedDict`，它定义了图中传递的状态对象，包括 `messages` 和 `sender`。`messages` 用于存储传递的消息，`sender` 用于跟踪消息的发送者。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5046c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "# 定义图中传递的对象，包含消息和发送者信息\n",
    "class AgentState(TypedDict):\n",
    "    # messages 是传递的消息，使用 Annotated 和 Sequence 来标记类型\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # sender 是发送消息的智能体\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c47fc6",
   "metadata": {},
   "source": [
    "\n",
    "### 8. 定义工作流（状态图）\n",
    "\n",
    "我们现在将所有内容组合在一起，定义多智能体的完整状态图。\n",
    "\n",
    "#### 注释说明：\n",
    "\n",
    "- `StateGraph(AgentState)`：用于创建一个状态图 `workflow`，其状态由 `AgentState` 管理。\n",
    "- `add_node`：将智能体节点 `Researcher`、`Chart_Generator` 和 `call_tool` 添加到状态图中，每个节点对应一个任务或功能。\n",
    "- `add_conditional_edges`：为节点添加条件边，基于 `router` 函数的返回值来决定下一个要执行的步骤。\n",
    "  - `continue`：继续到另一个智能体节点。\n",
    "  - `call_tool`：调用工具节点。\n",
    "  - `__end__`：结束流程。\n",
    "- `add_edge`：将开始节点 `START` 与初始节点 `Researcher` 连接，定义工作流的启动顺序。\n",
    "- `compile`：编译状态图，准备好执行任务。\n",
    "\n",
    "#### Graph 对象关键方法 API\n",
    "\n",
    "- **add_conditional_edges**: https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+conditional+edges#stategraph\n",
    "- **get_graph**: https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+conditional+edges#langgraph.graph.graph.CompiledGraph.get_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd89bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个状态图 workflow，使用 AgentState 来管理状态\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 将研究智能体节点、图表生成器智能体节点和工具节点添加到状态图中\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Chart_Generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165418d2-f5d1-4c25-ad5e-de5f6080a67d",
   "metadata": {},
   "source": [
    "\n",
    "#### 定义路由函数\n",
    "\n",
    "接下来定义边逻辑，以根据智能体的结果来决定下一步操作。\n",
    "\n",
    "#### 注释说明：\n",
    "- `router` 函数是工作流中的一个关键逻辑，用于根据当前的状态和消息内容来决定下一步的操作。\n",
    "- 如果最新的消息中包含工具调用（`tool_calls`），则返回 `\"call_tool\"`，表示需要调用工具。\n",
    "- 如果消息内容中包含 `\"FINAL ANSWER\"`，表示任务已经完成，返回 `\"__end__\"` 来结束任务。\n",
    "- 如果没有满足以上条件，则返回 `\"continue\"`，表示继续任务并执行下一步操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013c7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# 路由器函数，用于决定下一步是执行工具还是结束任务\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    messages = state[\"messages\"]  # 获取当前状态中的消息列表\n",
    "    last_message = messages[-1]  # 获取最新的一条消息\n",
    "    \n",
    "    # 如果最新消息包含工具调用，则返回 \"call_tool\"，指示执行工具\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    \n",
    "    # 如果最新消息中包含 \"FINAL ANSWER\"，表示任务已完成，返回 \"__end__\" 结束工作流\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return \"__end__\"\n",
    "    \n",
    "    # 如果既没有工具调用也没有完成任务，继续流程，返回 \"continue\"\n",
    "    return \"continue\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c9182",
   "metadata": {},
   "source": [
    "#### 定义条件边逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1c9c19-2858-4014-9e40-3dd6f30d92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 \"Researcher\" 智能体节点添加条件边，根据 router 函数的返回值进行分支\n",
    "workflow.add_conditional_edges(\n",
    "    \"Researcher\",\n",
    "    router,  # 路由器函数决定下一步\n",
    "    {\n",
    "        \"continue\": \"Chart_Generator\",  # 如果 router 返回 \"continue\"，则传递到 Chart_Generator\n",
    "        \"call_tool\": \"call_tool\",  # 如果 router 返回 \"call_tool\"，则调用工具\n",
    "        \"__end__\": END  # 如果 router 返回 \"__end__\"，则结束工作流\n",
    "    },\n",
    ")\n",
    "\n",
    "# 为 \"Chart_Generator\" 智能体节点添加条件边\n",
    "workflow.add_conditional_edges(\n",
    "    \"Chart_Generator\",\n",
    "    router,  # 同样使用 router 函数决定下一步\n",
    "    {\n",
    "        \"continue\": \"Researcher\",  # 如果 router 返回 \"continue\"，则回到 Researcher\n",
    "        \"call_tool\": \"call_tool\",  # 如果 router 返回 \"call_tool\"，则调用工具\n",
    "        \"__end__\": END  # 如果 router 返回 \"__end__\"，则结束工作流\n",
    "    },\n",
    ")\n",
    "\n",
    "# 为 \"call_tool\" 工具节点添加条件边，基于“sender”字段决定下一个节点\n",
    "# 工具调用节点不更新 sender 字段，这意味着边将返回给调用工具的智能体\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],  # 根据 sender 字段判断调用工具的是哪个智能体\n",
    "    {\n",
    "        \"Researcher\": \"Researcher\",  # 如果 sender 是 Researcher，则返回给 Researcher\n",
    "        \"Chart_Generator\": \"Chart_Generator\",  # 如果 sender 是 Chart_Generator，则返回给 Chart_Generator\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10670029-c194-4e2b-b002-56218aabd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加开始节点，将流程从 START 节点连接到 Researcher 节点\n",
    "workflow.add_edge(START, \"Researcher\")\n",
    "\n",
    "# 编译状态图以便后续使用\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53b403f8-1dfd-40a8-93ef-47a4886226c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAF4AW0DASIAAhEBAxEB/8QAHQABAAMAAwEBAQAAAAAAAAAAAAUGBwMECAECCf/EAFcQAAEEAQMBAwgEBgoRAwQDAAEAAgMEBQYREiEHEzEUFRYiQVWU0QgyUZMjQlZhcdIXJDZDUlR0dbPhCTM3U2JjcnOBgpGSlaGyw+IlNYM0ZMHTZaKx/8QAGwEBAAIDAQEAAAAAAAAAAAAAAAEFAgMEBgf/xAA5EQEAAQICBQgIBQUBAAAAAAAAAQIDBBESEyFSkRQVMUFRYaHwBTRicYGx0eEiI1Oy0jJCcoLB8f/aAAwDAQACEQMRAD8A/qmiIgIiICIiAiIgIiICivSrC++KHxTPmpVYVoPB42bQ+npH4+q97sfXc5zoWkkmNu5J2Wq9ft4a3rK4mdsRs+P0dmHw/KJmM8smwelWE98UPimfNPSrCe+KHxTPms89H8X7tp/cN+Sej+L920/uG/JV3OuH3KuMO3m72vBofpVhPfFD4pnzT0qwnvih8Uz5rPPR/F+7af3Dfkno/i/dtP7hvyTnXD7lXGDm72vBofpVhPfFD4pnzT0qwnvih8Uz5rPPR/F+7af3Dfkno/i/dtP7hvyTnXD7lXGDm72vBofpVhPfFD4pnzT0qwnvih8Uz5rPPR/F+7af3Dfkno/i/dtP7hvyTnXD7lXGDm72vBofpVhPfFD4pnzT0qwnvih8Uz5rPPR/F+7af3Dfkno/i/dtP7hvyTnXD7lXGDm72vBofpVhffFD4pnzUqsK15g8bDofUMjMfVY9uPsOa5sLQQRG7Yg7LdVY2b9vE29ZRExtmNvw+rixGH5PMRnnmIiLa4xERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBYx2f/uD05/N1f8Ao2rZ1jHZ/wDuD05/N1f+jaqv0n6t/tHyqXHo7pq+CfREXk12IvjnBjS5xDWgbknwCo2f7btFYLR+oNSR6ixmWo4SEy22Y29DM8O8Gx9H7B7neq1pI3JAWUUzV0QxmqKemV6RUjTfbPo3UehqmqxqTEU8VKyITSz5GEMqzPja/uJX8uLZAHDdpO6mpdeaagwlXMyaixMeItSNhr5B96IV5nuJDWsk5cXEkEAA7nZTNFUTlMEVUz0SnUWWau+kroDSU+nWO1FjMhDmr5ost1MhXdBW4jd8kr+ezWt3AJ69XAHbdaZSu18lTgt1J4rVSxG2WGeB4fHIxw3a5rh0IIIII8d0qoqpiJqjpRFVNU5RLnREWDNAdoH7g9R/zdY/o3LZ1jHaB+4PUf8AN1j+jctnXrPRnq3+0/KlSekemn4iIitFOIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLGOz/APcHpz+bq/8ARtWzrGOz/wDcHpz+bq/9G1VfpP1b/aPlUuPR3TV8E+iIvJrtCa3pUMnovP08rJNFjLGPsRWpK+/eNhdG4PLdgTyDSdtgeq8a9nr6+b7Ne1bQemqWL1ngqmlXPoalx+ENOxPK1r+5q2AWjvJ27lzXDruCT6x6e5UXTavaumYyz6Gi5a05ic3ii/2q6Zk7C+zvF6dbicdhnz1aWpc1c095XHirTKrd3OhfHwfK5wLe8IcBt49d1Q8XUpXuyXL6dllfkcUe1KiWMnpCkJqs7W8XiANaImSNBcGgAbHoAv6Jot8YqKeinrz6fs0zh5q6avD7vNP0otPaZ0ZN2W5mzgqNTS2J1G05J8GPa6GCF8bty9jGn1C4Dfp47e3Zeg9M5PG5nTmLv4YsdiLNWKamY4jG3uXNBZswgFo4kdCBt9ik0XLVc0qIpnqdFNGjVMx1iIi0tqA7QP3B6j/m6x/RuWzrGO0D9weo/wCbrH9G5bOvWejPVv8AaflSpPSPTT8RERWinEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQFjHZ/+4PTn83V/wCjatnWIaTdlMPpbD0LGm8yLFWnDBIG1dxyawA7Hf7QuLHWLmIw+japznSj5StcBXTRNWlOSzoo3zne/JzN/Cf+Sec735OZv4T/AMl57m3F/pyt9fa3oSSKN853vyczfwn/AJJ5zvfk5m/hP/JObcX+nJr7W9CSRQ93UFjHUrFuzgMzDWgjdLLI6p0Yxo3JPX2AFKWoLGRpV7dbAZmatPG2WKRtTo9jhuCOvtBCc24v9OTX2t6EwijfOd78nM38J/5J5zvfk5m/hP8AyTm3F/pya+1vQkkUb5zvfk5m/hP/ACTzne/JzN/Cf+Sc24v9OTX2t6HS7QP3B6j/AJusf0bls6xDVjspmNLZihX03mTYtU5oIw6rsOTmEDc7/aVt69DgbFzD4fRu05TpT8oVGPrprmnRnMREXaqhERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREFd7RunZ7qfcbjzXa6f/E5Oznr2e6X6bf+l1en/wATV97RTt2fanO+3/pdrr9n4JydnR37PtMdd/8A0ur1+38E1BYUREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREFe7ROnZ/qb+a7Xgdv3p3tTs7O/Z/pk//AMXV8Tv+9N9qdov9z7U/812vH/NOTs66dn2mPD/2ur4f5pqCwoiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAi4LV6tRYH2bEVdp8HSvDR/zXR9KsJ74ofFM+aziiqrbEJySqKK9KsJ74ofFM+aelWE98UPimfNTq692TKXS7Rdv2PtT7+Hmu1/ROTs52/Y90xt4ea6v9E1eb/wCyBdmeJ7ZOxZ+Qxl6la1Fplz71SOOwxz5YiAJ42jfqS1rXfpjA9qf2P3szxPY32LMyGTv0quotTOZetxyWGNfFEARBGRv0Ia5zv0yEexNXXuyZS9ZIor0qwnvih8Uz5p6VYT3xQ+KZ801de7JlKVRRXpVhPfFD4pnzXeq3q15hfWsRWGjxdE8OH/JRNFVO2YMnOiIsECIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiD4TsNz4LOMzqy7qlxZiLbsfhfZeg2762PtjJGzI/scByd4tLRs50l2n35H08fhInOb50mLbDm+IrMHKQf6x4Rn80h267KHA2Gw6Bbs9VTFXXPR3R54cMrTCYeK/wAdaKj0ph2TGZ+OgsWHHd1iy3vpXfpe/dx/2rn8wYz3dU+4b8ljuo/pCaiwuZ1uaegPO+nNITiPJZGDMMZY4CBkz3srujAdxY/fbvOuy0yx2k6VoUMTbv6hxmLiysLJ6QyFuOu6drmhw4h5BPQjwWmbtyrbNU8VrTVR0R1JbzBjPd1T7hvyTzBjPd1T7hvyXUy2tNPYC/To5PPYzHXbv/0ta3cjikn67eo1xBd1+zdfMprfTuDy1bFZLP4vH5S1t3FK1cjiml3Ow4Mc4Od16dAo1le9LLOl3PMGM93VPuG/JPMGM93VPuG/JdHKa603hMxXxOR1DiqGVs7dxRtXYo55d+g4sc4Odv8AmCZbXemsBcdUyeosVjrbTG10Fu7FFIDIXCMFrnA+sWu4/bxO2+yayvekzpd7zBjPd1T7hvyTzBjPd1T7hvyXSs6603Sz8WCsahxUGbl27vGy3Y22X7+G0ZdyO/6FWez/ALaMHrYy1bFvH4jMjI3aMOJlyDHWJ2153xd41h4uId3ZdsAdvDc7bprK96UaVOeS5+YMZ7uqfcN+S4H6Uw75hMzHQV7DTu2xWb3Mrf0PZs4f7VxZTW+ncHlq2KyWfxePylrbuKVq5HFNLudhwY5wc7r06BfMhrrTeJyXm+9qHFU7/exQ+S2LsUcveS790zgXb8n7HiNt3bHbdTF25TtiqeKZ0eiVhw2rbul3CPL23ZDC+29Pt31QfbIQNnx/a4gOb4uLhu5uj+KzIgEEEbgqY7ML8jKWQwkri7zXMG13O8TWeOUY/wBU84x+aMe3dbs9bTNXXHT3x548c6jF4eKI06F2REWlViIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIM6180jXWCc4EtOOuNY72A97W5D9J9X/dK6ysHaPhZ72NqZGnE6e7i5/KBCwbuliLSyVg+08XcgPa5jR7VW69iK3XingkbNDK0PZIw7tc0jcEH2ghbLu2iiqOzLxmf+r7BVRNvR7HkLWOjtRahyvbbcxWWyUuJrZ2uctpil3bPOtMU4DYjbLx7xshjJADXbO247dd11rWR0nd7QNU5HOavm01pzN0KD9PTR4mpbrXscKzWmCIz1pSHMkDw6JpB3dvxJ6r2Ui5826bHXE+dv1eSda1NOdi+WwNjA5VmptQwYjHY/wBGdQY82J8rVbKRC6vJwBjnbycdgCPVbyaOhUbk8LgZtX9peD7QdX5DTmRzGanMNLzRUsHIUZA1tZ0EslWSR3FmzNmP9RzNwGnqvZCJmTZ7/PF447fJYbfp9pbI5GPH28VhK9fEVhiIrWS1CRW5CZ0zo3OLWybt3i4lha5xcFpXZZWxuqO3TOZyaODJTHSODkr3HtDzxl79znNJ/hcWnf8AMt9RRmmLWVWln52vNnYfqLRWmITpvV8NaDtMkz9l9uO9RdJas2X2nmCwx3AlzOBj4yA8WgeI23VWnwONq9gmoc5Dj6seZh7QXWI77YWidsgzrIw7ntvvwJb4+B2XrxEzNVsyzeN8nhcDNq/tLwfaDq/IacyOYzU5hpeaKlg5CjIGtrOglkqySO4s2Zsx/qOZuA09VrPZnpShV7f+0Q2IxkbmNxWDqwXbjQ+biIpuTuW31nGNhJG3Vo+xbeiJptZTn56/qLs6BaTrrPOaCGjHUmvd7Ce9s8R+ket/vBdKzZip15Z55GwwRML5JHnZrGgbkk+wAKydnGFnoY23kbsLoLuUn8oMLxs6KINDImH7DxaHEexz3D2LptbKK6p7MvjnE/KHPjaoi3o9q3IiLWoRERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQERcc1iKs1rppWRNc5rGl7gAXE7ADf2kkABByLO9aadGl61/PUbVOnjYmvtXquQnbXrxgAufKyU9I/aXB3qk9d2EuLrDX1Dez5qvw1Esx83lDJb+RZJA6JzPVjcyBzQ6Vrn7kElgLW8g4hzd+fFaViqWquQv2p8rmYqYpvuzOLWvbz5uLYWnu2EuAJLW8iGsBJ4jbOmuae+Gyi5VbnSplmx1LFBAyW5RyVBr2h4dPRkLOJG4PeMDmeH+Eodva7o595lJuoKbrj3cG1w4944/YG7bkq99tGk8Z2r6Jz/AGe24JrU+Wx7pGtY+WBkJbIwxSOnY1wYRJxe1p3LxG/1Xta8Lyn9BT6G2f7Iu1LVeo9b0GR3MK92NxErDyisl7Q59qJ3Qlpjc1oJHi97SA5jgM/yeumeP2d8Y+vrh6H9MMT/AH+T4eX9VPTDE/3+T4eX9VbOifkbs8Y/inl9W6xj0wxP9/k+Hl/VXFBrrCWmudDdMzWPdG4xwyOAcDs5p2b4gjYhbYq3o2QC1qWsPNDTWy0jTHiWlrmF8UU37YH9/d3vMkeLXsPtT8jdnjH8Tl9W6zz0wxP9/k+Hl/VT0wxP9/k+Hl/VWzon5G7PGP4nL6t1iF/tB0/iqklq7kW06se3OexE9jG7nYbuLdh1IH+lR2G7XdK6ny0WKwGUiz2VlJEdOgQ57tgSdi4hvQAnx8Atr1VpjG6003k8Dl6zbeLyVd9WxC78ZjgQdvsPXcH2HYrw39GT6C+U7J+1XV2rc3jaeohpu26vpmhcLovK3/g5W3Q8gsBbG8sZuHDvee5jMQcn5PVTPH7InH19UQ9f6f0TcuWYb2oBFG2JwkhxcLu8Y1w6h8riBzcPENA4tPXd5DS2zZHL2cfkq0IxNq3Skilklu1yxzYHMG4a5hcHuLuoHBruo2O24K56OXqZGxcggkJnpy9zPG5pa5jtg4dCOoIcCCOh38V3VhVXNXdDgruVXJ0qpROG1Vis82t5HcaZrFcWmVJ2ugsiLlx5OheGyNHIEHk0bEbHqpZdHJ4PH5hj23KkU5fDJXMjm7PEbxs9ocOrQR47EeAUS7TOQxcR8yZqeFsONbSqUckPK6zJGH1JnuO073beq7eX1hsfrbk4NayIq3b1NkMHFkZ8rhbD6NOCGRtnFNdcfO53SRra7GmXdh67Brt29R19VStDPY3KXr1KnkKtq7QcxlytDM10tZz2B7BI0Hdhc0hwDgNwQfBB30REBERAREQEREBERAREQEREBERAREQEREBERAREQFxWbMNKtLYsSsgrxMMkksrg1rGgblxJ6AAddyupfzUVG5SqiGezPalMTRXiLxHswuLpHeDGgbdXEblzQNyQDG0NPW8kK9zUUzJ7bqbq1jGVnudjhzdyd6jgDI7YNZzePAEhrObgQ+S5+9m2Txaegj6Mryw5a63lSmZIeTjFwcHSlsfXpxaS5o5fW49itpOm206zefJmbDbzr9aTIhknkTywsAgAaBGGsLmggciHO3JLnEzaICgZsjdzVoQYlxqV69iB89+eDnFZiLe8cyA8hyJHAGTYtHMhpLmuDfzO2bVM8tcslr4VhsVbkNmsY33d2hg4EkERjeT1uILi1pa7j1dOQQR1oY4YY2xQxtDGRsaGta0DYAAeACDrYjD08DRbToQCvXD3yloJcXPe8ve9xJJc5znOcXEkkkk9Su6iICIiAq9hZwzVupKZlxYd+1rYgqNLbQa+MxiSx/C5GBzWO/gx7fiqwquyzCl2gQMdLjIhkMa5rYyzjemdBID0d+NEwTu9X8Uv3H1igsSIiAiIg6ORwlPK2KNizDznozd/Xla4tdG/iWnYgjoWucCD0IPUKJp5W9p2CCtqGZtpsdeWabPMibXrNDX7NErS8ljyxzSXD1CWvPqeq1WRcdivFbgkgnjZNDK0sfHI0Oa9pGxBB8QR7EHIigDXuadtGSsJsjjrM8Mfkm8bBjoxHwLo+g5M3awlpO45SOBPRimaluDIVIbVWaOzWnY2WKaF4eyRjhu1zXDoQQQQQg5lGZ3TWM1LTfVyNVs8T3McSHFjw5juTCHtIc0tO5BBG25+1SaIICXD5mnYfLjsyJmT3455q+UgErYq+20kMDmFhYT9Zrn95sdxtsRx/MOqpa00EGXxVvGzWbslOu6JjrUMgHVkjpIwRE148DLw9YcfEt5WFEHBRv1snVjtU7EVutIN2TQPD2O67dCOh6hc6hfRHGxXqVqpHJjn1ZppxFRldBDM6UbSGWNpDJNzs7dwJDhuCDvv1KlvUGCr04cpFHnY468z7WUoRGF/Nh3YBW3cXFzem7HH1x0YA7ZoWVF0cTmaebpwWakpcyaFlhrJGOilax+/EujcA5hOxGzgCCCCNwV3kBERAREQEREBERAREQEREBERAREQFX79+5nnWKGHnfSiMQPnyIRTMY/viySKNpJBlaGSblzS1hLNw/1mjns2LmUyzqVV1vGwUpIZZ7ZrsLLQPJxgjc4k9Nmc38CNpOLXB4cY5KhQrYqjXpUq8VOnWjbDBXgYGRxRtGzWNaOjWgAAAdAAg4cbhqOHNs0qsVZ1ud1qw5jdnTSu2Be8+LjsGjc+Aa0DoAB3URAVavTR6wuWMVBJUt4WEyVstwnkEwlAYWQN4bDYhxLyXdAA0tPMlve1NkZqNCOGqy2bl6UVIJqtXv8Ayd7gdppASGhjNi4lxAOwaN3OaD38fT8gowVzNJYdGwNdPNx5yH2vdxAG5O5OwA3PgEHNHGyGNscbQxjQGta0bAAeAAX6REBR+d/9rm/1f/8AQpBZV9KfMZrAfR71zkNPPmiy1fHudFNXG8kTeTRJI3/CawvcD7CEE0i8zawwmhdBdiurcx2UWqY1JLp98rb2OvGe5NV5M72y4cyXPaDv3hG4J8Rvsq9q3E6Q0ZqClR7NJ4HUcro7NS5uOhaM7J67KzTWszdSO8MhIEh9Z3Jw3KD10qvS7QcXm9HXNTYdlnL0ajrTe6q13Ged8D3xyRxMdsS4vjLWjpudvYd1geitHYjS2f7AruMqCva1NibFfNSmRz3ZFhxnffhy4nns9oI38PAbDoq7o/Qmh4/oodqEEWHxDM7FWz4uRMjYLDTWsWXV+Y+sO72iLd/D1fzIPX2OuecMfWtdxNV7+JsvcWGcJY+QB4vb7HDfYj7V2F5lwWhsB2idsGJx+ocfHl8ezs5xj/JJ3OMRkFmdvMsB2Lm7u4uPVu5223UP2IZ57s/2J38zf3MulMzSjtXJesrorVcNaXOPVwjj3+3YEoPWSn9Mf2ux+kf/AJX8/LOSfqQYzGxZbFV9GZ7X+pHWbmUZJNjbMgfzqRy91NFyY/eQtBfxc5rdw7bZervosaLOi8PqaCvqTEZvGzZBroKWCjeypjXiNokiYHzzFu52eWcgAXHYDdBuKIiCiv8Aru/SuM/g3dNy0nbYDwP2rzZ2e4jQ2r9V6zzfaBZpz61xuqrNeIZS8YpcfCyYCnHA0vHFjmcHAtH4QvO/LwWfahjxD+y/WesrlwfszVNS2K9OXyp3lsFht4R1qkTOW/dOh4DgBxc17id/FB7XUO3VuLdrB+lxYJzTKDck6Du3bCB0hja7ltt1c1w2336foXl3WWicTnKH0kc7eqOkzOEmfaxlszP50po8XBI2SEg+o8ua3dzdiQACSAArJjsDpXKfScxGa1DQxTspb0ZQycFq5Gxrn3WWHN71hP741vdDcdQA1B6Bwmf89WstD5tyFDzfaNXvLsHdss7Ma7vITuecfrbcunVrht0UqvG1nTGMr1M1gq9UU8TJ2y1q7q1VzoR3b6tcPaC0ggODnA7H2lc3aPh6OiqXbRgMRAzGacx9zSuTjow+rBVL7jDO9rfBgIha523ToSg9hrv4P/3SD/W/6SvInb7rG5V7RNb3dIX22M1Q7OZD3lCQSSVw68wucOJ6OEZc8e3oD9is/wBHfs1pYrtO0znMBrPSTqr6M81jHabrTxy5WB8ezZZ+9uTciyR0buZby3JBPrIPU+Z0pQzL7Fjg6jlJappty1LaO3FHyDw1sm2+wcA7id27+IIJB68+Sy2DntSXq3nPGmavHWfj4i6zG1wDZHTM32cGv9blH14u+p6hc6wog4Kl6tkInSVbEVmNsj4nPheHgPY4se0ke1rmuaR4ggg9QudQ1jTUbb8N3HzPxk7JZZ5oqwa2G698fA9+3b19uLHBwIeOAHLiXNd+sLm5Ljo6WRhio5xlaOezThldNG3kSCY5SxneN5NI34tO3Hk1vIBBLoiICIiAiIgIiICIiAiIgKG1BlJq76uOx8tE5e44Ojr3JzGTA17BPK1rfWcWNeNgNhycwFzQ7cTKrWl7UWoMnlM3DcqZCmJpKFN8Nbi+EQvMdhhkPV+8zHjp6vqN23O5ITGGw1PT2KrY7HwCvTrM4Rx8i47e0lxJLnE7kuJJJJJJJJXdREBEX5kcWMc4NLyASGt23P5huggaNeXIauv35616qyhGKNYy2P2vZa8MkklbEPaDtHyd19RwaACS6wKA0JjTjNK0RLjH4e5aDr1yhJa8qdBZncZpmGX8faSR43HTp0AGwU+gIiICj88A7FTAjcHbcH9IUgiDJsFoDTGlrNmxhtOYjEWLQInloUYoHzAnc8y1oLv9K/OI7PdLafgyEGL01h8bDkGltyOpQiibZBBBEga0cwQT47+JWtogzNmm8RG7Fubi6TXYppZjyK7AabSzuyIen4McPV9Xbp08F0naB0w69lLp05iTcysLq2QsGjF3lyJw2dHM7jvI0gDdrtwdlrKIMyq4DGUMm25BjqsFwVW02WIq7GyNgYSWwh4G/AEkhvgCTsujc7PNK5DC1cPa0zh7OIqv7yvj5qET68LtyeTIy3i07kncD2laVnsU7MY/uI7dqlKyWOdktSbun8mPDw0nYgtdx4uBBBaSNl+8HkZMvh6V2ajYxk88LZJKVsN72u8j1o38SWktO4JaS07bgkbFBm79Dablw1rEP0/in4m3K6exQdSjME0jjyc98fHi5xPUkjclWvs80/i9MYqShhsbTxNCNwLKtGBkMTSd99mtAAVrRAREQZRldA6YzWdizGQ05ib+Xg2EWQs0YpLEex6cZHNLht+Yr7NobTdjUbNQS6fxcuejADMo+lGbTQBsNpePIdOnitWUbqLJzYnDWrFSGG1fDC2pVnsNgbPORtHGXn6vJ2w32J69AfBBQPRbDyw5iKTD0TFly7zhG6uxzboLBGe+G3r7sAb62/QbeC48ponTucOOOSwOMyBxxDqRtU45fJSNtjFyaeHgPq7eAWhaawFPTGEq42jXZVrwhx7tjnOHNzi955OJcSXOcSSdyT1Umgy12kMC573nCY4vfdbk3ONSPd1toAbYPT+2gNaA/wCtsB16Lmk03iJp8jNJi6T5slG2G9I6uwutRtBDWSnb12gOcAHbgcj9q0xEGT4HQWmdLSiTC6dxOIkbEYA+hRigIjLuRZu1o9UuAJHhv1Xf0HoPTOlM+61hNO4nDWrPLv5sfRigfL0J9ZzGgu6/atJRAREQF0sviosxU7iSWxXLXslZNVmdFIxzHh7SHNPUbtG7Tu1w3a4Oa4g91EERh80+ey/G5F9ODNRtdK6rWnL+cHeObHMA4NcA4AbjYhriW8nbBzpdRWoKFm1XinpWH1blaRsrXRQxyOlYCC+H1+gDwOO4LSDsdxsuzh8pHm8RSyMMU8EVuFk7IrULoZmBzQQ18bgHMcN9i1wBB3B6hB3EREBERAREQEREBERBF6oztXS+msrmL1jySnQqy2ZZ+5dNwaxpcTwb6zz0+q3qfAdSuXA0rWNwePqXrxyd6CvHFYvOhbCbMgaA+UsZ6rS47u4t6DfYKM11kPIMNXa3LSYaa1kKdWK1DW79xc+wwGPjtsOY3YXHo0OLvYrEgIiICr3aDQdl9FZjHDEefmX67qUuO8r8l76KX8HIO9BBZ6jnHcHfp067Kwqua4xvnehjarsO3NQ+dKU74n2u4EHdTsmbPvv65jfGx4Z+MWgeG6CwsY2JjWMaGMaNmtaNgB9gX6REBERAREQEREBERAVYsRw6Rzr7zI6VLE5WUHIWp7Ric227uoYOLXHge86R9NnF3d9Hcjxs6oHbnkda4rs1yljQGnsXqjUTePHG5eQthkj39fZg27x23gwvZvuTyJAY4L+i8CfQE7VO0HWv0g+0ap2kXsjPqJ+Ig76vkIRXdB5PNwawQBrWxgd847Bo6vc7xc4n32gIiICrGLkr6zyFfMsdRyGEquL8ZJ5O4ytstMsUs7Xu2HEscWMcwdWue4Pc1427OSlmzl52LrGeGmzZ1vI07UbHxva5jvJ9urwXsPrH1SGuBa7kQRPICIiAiIgIiICIiAiIgKv4KKTGZ/NY/uci+rI5mRiuW5u9hLpS9skERPrNDDGHlp6DvhxO27W2BV3N0zHq3TeSix1m3NvYoSWIZ+EdWGSPvS+Rng8GSvEwbdWmQbdC5BYkREBERAREQEREBERBXNX5DyO3puEZWXGPt5VkLWxV+98q2ilkMLj+ICIyef8Ag7e1WNV3VWQ8iy+k4vO0mN8ryjoe4jrd6L21Sy/uHO/ex6nec/tiDfxlYkBERAVd1bjfOVzTe+HblmV8o2d0rrXc+RcYZdpwP3wgkM4f4zl+KrEq7qrG+cMvpOU4YZUVMo6fyk2u583/ALUss8o4/vu/PuuH+O5/iILEiIgIiICjc/n6mnKBtWi53J3dxQRDeSeQgkMYPaTsT7AACSQASJJZTZyLtSakyGReeVWrK+hSYfBoY4tlkH53PBH+TGz7SttFMZTXV0R5y89TosWtdXo9T938jnNRcjdyEmLrO2LaWMeY3AfY+b67j+dnAfmPiox+k8bI4ukZYmcfF0tuZ5/2lxXY1FqHHaTwd7M5e3HRxlGJ09ixKfVYwDcn7T+gdSegVI0x22QanbZm9D9WYrHxUpL8eQymObDBPEwA+qe8JDnA7hrw0kb/AGLHlF2P6Zyju2L6Ldq3+GIW70PxP8Wf9/J+snofif4s/wC/k/WX60fqerrXSeG1DRjmipZWnDegjsNAkayRge0OAJAOzhvsSPzlS6cpv788ZbIppnbEIb0PxP8AFn/fyfrJ6H4n+LP+/k/WUpctxUKk9qw/u4IWOkkfsTxaBuTsPzBdPTeoKOrNPYzN4yUzY7I1o7daRzC0vje0Oadj1G4I6FOU39+eMmjR0ZOgOz/T4veWjHM8s7vuvKO8f3nDffjy3323AO35lz+h+J/iz/v5P1lzan1Ni9G4C9m81cjx+LoxGaxZl+qxo/R1JJ2AA6kkAdSqhovtlh1pmq9BmkNW4eG1E6Wtkcti+5rStA3+sHEsJHUB4bv7E5Rf354yiYoicphafQ/E/wAWf9/J+snofif4s/7+T9ZTKJym/vzxlloU9iCg0NhKrCyGl3LC5zy2OV7QXOcXOPR3iSSSfaSSuT0PxP8AFn/fyfrKZROU39+eMmhT2Ib0PxP8Wf8AfyfrJ6H4n+LP+/k/WUyojD6sxmfy2bxtGczW8NOytdYWOaI5HRtkDQSNneo9p3G467eO6cpv788ZRo0dj4NIYpp3EEgP2ixID/1LtVaV/DnniczeqOHhDanfbgP5iyRxIH+Q5p/Ou8icovddUz79vhKJt0VRlMLRpXWBzEpoZCFlLLMbz4MdvHYb7XxE9SB03aerSR4gtc6zLJcpVmsVg+nI2vkK7u+qTuG/dSgHYn8x3LXD2tc4e1aPprOR6lwGPykTDE21C2UxOO5jcR6zD+dp3B/OFlMRVTrKfj571HirGpqzp6JSaIi1OIREQFXdbUTbp4uVmMnystbKU5mRV7Hcui3max0xP4zY2Pe8s/GDSPEhWJV3X1Hzjp1sXmyfLlt6lMKtax3D92WoniTl9jOPMt/GDC32oLEiIgIiICIiAiIgIiIK9qjJNoZfSkLso/Hm5lHQNgbXMoukVLEnclw/tYAjMnI+2IN/GVhVd1VkTRy2lI/OsmOFrKOgMDK3ei9+1LD+5c796Hqd5z+2IN/HViQEREBVzVWO8tzGkpfMnnbyTKun8p8p7rzb+07LPKOP77vz7nh/j+X4isarmqqAuZnSMpxc2QNXKumE8U/dtpHyOyzvnt/fGnn3fH7ZWu/FQWNERAREQFi2iSXaTxbiS57oA55d48z1dv8A6d1tKyaOi/AZvKYeQEMZM63VcfB0ErnOAH+Q/mzb2ANP4wW6NtqqI7Yn5x/2FngaoiuYnrZZ9K2lPa7F8lNHWku1KVylevVYm8nS1YrMckw29oDWlxH2NKns52naR1HpS7XxepcVkLORxdmWpBWtsfJMwQuc4hoO/QePTotAIDgQRuD4gqv4ns80rgJ7c+M0zh8dNcaWWZKlCKJ07T4h5a0cgfaCuRbTTOlnHW849m+kcVoal9HfPYWvJTymcqx1cpO2Z7jcifjHy8JASeQa9jC0eDeIA2HRV/R1+me0Lsy1vho8Dpwaozc8L8ZSszS5Gau+Kfl5W90pa/12s9Xu/UcWgO9i9eR6Yw8UOKiZiaLIsVt5vY2swNp7MLB3I2/B7MJb6u3QkeC6EPZ1pSvcmtxaYw0Vuawy3LOzHxB8k7HcmSudx3L2u6hx6g9QVObTqZjLLz0MM7Mey7TuodH9pWWv4eHLZaXPahgiltM710TDPK3u4wfqtPUkDxLjvurr9FTGaZx/YppV+n4MdDZtYqpPkjR4B77Pcta90vHrz5NcDv13BWqY3EUcPFNHQpV6Mc0z7EjK0TYw+V7i573AAbucSSSepJ3Kq97syq13SSaVunQs1iQy3ZcDjqTXXXewymWB+5G7tiNj6x33UM4t6GUxCp/Smgk/Yzq5B1eS3i8Tm8dk8pXiYXmSlFYY6b1R4gAciPsaT7F19U9tpbr7s8raX1FpvM4HUVwVJ6sLu+t8e7kkMzHNl2DBxY0gsOxd4+xaFpnS2Wwtmd+T1flNSwyR8BXyFanGxh3+sO4gjJO3TYkjr4LlwfZ5pXTOQlv4fTOHxN6XfvLNGhFDK/fx3c1oJRM01TOcbHk7s10de7QsbS1Hf1npnBa6fmXNtWbFax55r2mWSDV5G4G8S1vAR91xLHDZvtXf1ZpjGjs47adYiufSbCarty43Jd47vaZZJA8CI7+oCXO5Abct+u69TP0JpqTUIz7tPYp2dG22TNKI2Rt0H4Xjy/5rnm0lg7GPyFCXC4+SjkZXT3az6sZitSO25Pkbts9x4t3Ltydh9inNqixsyeW9XYE9oXat2kw6l1BpjES4iaKOg3UkE7pKdI12ObYrPbbhawF5eS4NJDh1dtsBa8J2Z0M/28MxmrpWaukxmhsWySey09zbnFmwPKHR7kF3qkgnfbmSFuee0NpvVNutazWn8Vl7Vb+0T36Uc74uu/quc0lvX7FIR4ehFk35JlGszIyQtrPttiaJnRNJc2Mv23LQXOIbvsCT9qZsos7c57XjuzkKdnXWlNfYmLBaanyeuG40wR2Zn5e1GbL4J+/cZeDWO2J7ruyGgs2cPBXLB4DC6d15285DC4zGwa7qyST4faJgtc5cayT8GPEh8vNx28Ty/Ot8l7OtKTXrt2TTGGkuXXNdasOx8RksFrg5pkdx3cQ5oI332IB9i7k+ksHaz8Gdmw2Pmzddndw5KSrG6zG3Yji2QjkB1PQH2lM0RZmHmXR1PS2Au9iOU0TdZa1RnpmjMyw23Sz5Cs6nI+1JaHI8iyUMO7vqu6DbwV8+iborD0OzqnqRlNr87bsZKGS9IS6QQ+Xy/gmk/VZvG08R05bnxJWs4jRGndP5S3ksXgMXjcjb38ouVKccU0253PN7Wgu69epXfxWIo4KiyljaVfH02Fzm16sTYo2lzi5xDWgAEucSftJJ9qhlRa0Zznz0fR21O9k7i7SUg3Lo25G+GE/Z5VLuP0A7j9AVYyt446jLOyJ1iYbNigj+tLITsxg/O5xA/wBK0DSODdpvTWPx0kgmnhiHfSt8JJT60jhv9ri4/wCldVGyzOfXMeGefzhx4+qNGKetMIiLUphERAVd1/S84abdD5rnzH7bpv8AJa8/cv8AVsxO58vsZtzI/GDCParEq7r6icjpt0AxtjLHyuo/yWtY7h542Ync+f2M25kfjBpb7UFiREQEREBERAREQEREFd1bkPIL+mR53kxbbGUEJiZW74Xd4JiIHH97G4D+f2xgfjKxKua0yAxseFldl5MTG7K1oXd3X77ynvHFjYHfwA5zm+v7NgrGgIiICruqKBu5rSUoxk18Vco+Y2I7PdNpDyOyzvnt/fWkvEXD2GZrvxFYlXdS443s9pKbzL5zbTyMk5ueVd15u3p2I++4b/heXed1x67d9y/EQWJERARF1Mjl6OHZA+/dr0mTzMrROsytjEkrzxZG3cjdzj0DR1J8EHbULqjTEOpasY7w1b1cl9W2xu7onEbEEfjMPg5p8engQ1w4GaskvyxtxeHv3o25B9CzNNEajIAz68v4bi6Rm/qh0YcHHwO27h9p0NQ25sfYyOTgo9xNM+eljYg+OxGekTHSSN5eqPWJYG7nbwAIOVNU0znCYmaZzhQMlk5dMSNi1BXONJPFltu760vTclrx9XwPR/E/pHVfI9S4iUEsytJ4HTdthh//ACtDw+icPhW45zKzrlvHsljrZDJSvt242yu5SgTyl0mzjtuOW2waPBoA7s+n8XafzmxtOV/8J8DHH/mFs/Kq2zEx7p+v1WdOOqiPxRmzL0hxfvKn9+z5p6Q4v3lT+/Z81pPothfdFD4ZnyT0Wwvuih8Mz5KNGz3+DPl/ss29IcX7yp/fs+aekOL95U/v2fNaT6LYX3RQ+GZ8k9FsL7oofDM+SaNnv8Dl/ss29IcX7yp/fs+aekOL95U/v2fNaT6LYX3RQ+GZ8llP0n9f6f7BuxnO6oOLxwyXDyTGRurR/hLcgIj6bdeOznkfYwpo2e/wOX+y7vpDi/eVP79nzT0hxfvKn9+z5rzH/Yz+12tr3E6g0FqKvBksvjuWVp2rMLZHvrveBK0uI/Fke0j/ADp+xe5fRbC+6KHwzPkmjZ7/AAOX+yzb0hxfvKn9+z5p6Q4v3lT+/Z81pPothfdFD4ZnyT0Wwvuih8Mz5Jo2e/wOX+yzb0hxfvKn9+z5p6Q4v3lT+/Z81pPothfdFD4ZnyT0Wwvuih8Mz5Jo2e/wOX+yzU6hxQBJydPYf/cM+a4odTUshKYcW5+bs+Hc40CY7/Y5wPBn6XuaPzrUG6Yw7HAtxNFpHgRWZ8lIRxMhYGRsaxg8GtGwCZWY6pn4sZx85bKVO0fpZ8liPMZR8E1uJzm1q0D+8jpnYsfu7wdL1c0nb1Ru0eLnOuign6IwonjmrU/Nsrb5yb3Y2R9Tv7BHFz5hEWibkAA4ScgdhuOg246uKz+MkpsjzUeUq+VSPtHJ1mifuXdWMjfFwaOB6buY4ub4nccjjVVNUq2uuq5VpVdKwoq7Q1PdY3FQ5jCWsdeu9/3gq7269cx7kc5mgbB7Ru0uaN/qnZ2wMlgtQYzU+Lr5LEX6+SoWG84rFaQPY4bkHYj7CCCPYQQeoWDBIIiICrmv6IyOmXwnG2Mt+2qj/Jas/cyHjZjdz5fYzbmR7Q0j2qxqu6/pi/peeE4yxmPw9d/kdWfuZHFs8buQdv4N25Ee0NI9qCxIiICIiAiIgIiICIiCu6+yHmjTMl45SXDRVrNWaW1DW8od3TbEZkjLP4MjA6MuHVoeXDqArEo7UVS1kNP5OrSvS4y7PVljguwRtkkryFhDZGtd0cWkggHodtivun8tBn8DjsnWkM1e5WjsRyOYWFzXNDgS09Wnr4Hw8EEgiIgKu6gxfl2qNLWDhhfbSsTzC+bXd+QONd7A8R7/AIXmHlm3s5b+xWJUbPXWZDXenH47AjOzV4Mk1uYju8IMbMwRMMUoG+5kJLOgc5hYfV25EBeVXclrOGIZSDEUrGocrQZC99ClxYT3p9T8LIWx/V9cjluGjfY7tDuM6RfnqxGp7DcqyzjxTu4hrB5tkJdykd3TgXO5dG7Pc4cW7ADk7lY4omQxsjjY2ONgDWsaNg0DwACCBvYrO5eTIwSZduIoumhNOXFxtNru27GUSOla9nrn1fVYC1u5DuRBb3KelsXRtWbMdQSWLFryx8s73TOEvHiHNLyeOzdwA3YAEgAbqVRAREQEREBERAREQF0s1l6un8Rdyd6QxU6cL55nhpeQxoJOzQCSdh4AEnwC7ckjYo3Pe4MY0FznOOwAHiSVAwyP1TarWoJrFfEV3x2a1mrajMeTa6IkH1dz3Q5tI9Zpc5h3BZsXh29LV7tXT1CPI3pcne7sOltTQNge8nr1jb0btvtt+b2qVREBERAREQEREBERAUXk9L4rL3YrtqjE/IQwS1obzBwswxyACRscrdnsDtgTxI6tafEAiURBW2YLMYdjRjMw63BXxrq0FLK7yd5YHWOWSx1kP8F2/LcbHx35H6tnxLHHO4mfHx18a29byFVws0mPHSWFjhtK4t8d3RNDmkEdQ5rbIiDgpX62SqxWak8dmvK1r2SxODmua4BzSCPYQQf0EKD7Qqbr2j78LcbYy7vwbxSq2O4kkLZGuGz/AGbbb/n229q5cxovGZZ+Qsxsfi8rdgjry5bGkQXCxjuUY70DdwaSdmu3HrOG2znA1/tJr5/0S1QwYv0tp2GNFXFYyXyG4GcfXb3znlr3cgHAgMOxI2cQOQX5FH4nPUc2642lP3r6dl9SwxzHMdHKzbdpDgD4OaQfAhzSCQQTIICIiAiIgIiICIiAq9pGxJGctjJ7N67YoXpAbF6Du+ccp76Nsbh0kYxsgiDh1/BEO9YEmwqAybZcdqnG32edbUNxpx0teuWvqwdHStsSMPVvVpj5N36yt5DYcmhPoigtX5aXG4+tDUv08fkr9qKnUkutc9jnuPJwDW9XOEbZHAbgbt6kDdB+JJbOpbXd1Z5KeLrTxSeX1LEbjccxxL4QAHcWBzQ1xJDjs9oAHrLq1dP1Keuqs1bT8FaGlipYYMlDYDAzvp2PlgEA/hGFjzIR4jYe1WHHY6ph8fWoUKsNGjVjbDBWrRiOKKNo2axjRsGtAAAA6ABQuIx7TrfUWTfiGVZ3wVKLckLXeOtxRiSRrTGP7WGPsSj7XcyfANQWNERAREQEREBERARFE5bU+OxE8lWSw2bJipLdjxddwfbnij25ujiB5OALmt3A25OaPEhBLKOyufqYeSpHN30s1mxHWjirQvmcHP32c4NB4sAa4l7tmgNO5UXYrZzU1aeJ8sumqFitA6N9Z7HZGOQkOlY7cPiZsPU3aXnq4tc0hpUxj8Jj8VYvT06UFWe9N5RbmijDX2JOIaHyOHVxDWtaCd9g1oHQAIIqPDXs8+GfOEV4WeUxOw9aUTVbET/UYZy6MF7hHv6g9QGRwPeFjHixIiAiIgIiICIiAiIgIiICIiAiIgKK1VjmZjS+YoSV5LcdqnNA6vFKYnyhzC0ta8fVJ32DvZvupVPFBA08PXzmN0/ev0Jad+nGyxCySU99VkdHs5he0+t0Ja4dQ7bqPBcmCt34HRYvKCW1ehriR2Sjrd3Xs+sWnbZzuD/qktO31vV3AO3BoCkcXo7F4/zZPh46MXkcVKxY8ofHFE4xxkybkuBa1rgSd9iN+u6+66oOtadnt18X55ymM3yOOp+VmoZbUbSY2d8D6gcd2En1S17g4FpIIWBF8a7k0Hbbcb7FfUBERAREQEREBdDO4avqHD3MbbMra9qMxvfXldFI3f8AGY9pDmuB6hwO4IBC76IIvTmQuZHGB+RpDHZCOR8U1YWGT8S1xDXcmgDZ7eMg3DTs8btadwOlqmcVsnpd77lGpCcnwe25FyfMXVp2sZC78STmWnf2ta9v4y8C/Ty7c+2PQOsbVHFYSbs+05cAg9IsTLzmzLY5C6JzrTWtdCWt2/BNIcObwXPa4AW76auu+2jSPZ7prXGkNUTs0XlsdXGRhio1XS0LMkQ2mZJ3XeRtfv0e127H+Dm8mAB7tVc0ZQbXbm7pxUeKs5HKTzzd3a8o8p4bQRzk+DS+KGI8B9UbA9QVQPovO1Bi/o1aSvaqytvNZubHPyU9vKWi+RzZXPmY10rzvsGOaN3E7AewAAaLobDswGkMRRZRhxro67DJUryuljikcOUga93Vw5l3rHqfFBOoiICIiAi6mWy9HA4yzkcndr47H1YzLPbtytiiiYOpc97iA0D7SVEWtR5C6b1fBYp1mxAK5ZZyLnVqkrZOrix4a5zyxnUgN2JLW8geRaFiUKdX42S9DUqSuycz7b6UnkDDOytKxvJ7Z3N3bFsCOjyDu5oAJIXDNpWXJ2JH5bKWrkDL0d2pWrudVjgEY9Rju7IdKOXrODyWuIHqgDZTdetDUjLIImQsLnPLY2hoLnEucdh7SSST7SSggaVfUOZZjrOSkiwLQycW8XSk8pMhcS2I+UFrC0tb6xDW/XOwe5rd3yeFwNLT9GCpSicyOGNsTXyyvmlc0Ekc5Hkved3OO7iSS4knclSCICIiAiIgIiICIiAiIgIiICIiAiLPu0qxddn9PUa2Rt4+GeK1JL5JJwc8s7rjudvZyP8AtWVMROec5RETPCM2u5cptUTXV0Q0FFknmq9+Ueb+M/qTzVe/KPN/Gf1Ln5Tht+eCp53w3fw+7W1B64Oom6SyrtJHHjUjYC6i3KxPkrPkHUMkDHsds7Yt3DhsSDsdtjQPNV78o838Z/Unmq9+Ueb+M/qTlOG354HO+G7+H3eRvoU9qHbFr76Rd7TGrM3ZrYrAyX8rl8R5LFXDrb+URa/iwOI7yYv7vfjyaHBu7QRev7JJrrX/AGaYbDXNLZ2xT09qOtPg8xQNeKaKQFri3bmxxjc9ksrS5haSGt6+q3bZqHZxQxepclqGneyNbN5OOOK7finDZbDY9wwPdx67A7f7PsCap7N6Gtq1Otn72Ry9enajuwRW5xIyOdm/B4BG243P+1OU4bfngc74bv4fdY/o15ftAz/ZBhMl2lQUKuobUbZGQUa5gc2Dg0MM7eRaJnbOe4MDWjkG8WkELUVknmq9+Ueb+M/qTzVe/KPN/Gf1JynDb88DnfDd/D7tbRZJ5qvflHm/jP6k81Xvyjzfxn9Scpw2/PA53w3fw+7W0WX6Vkv0Ne46o/MZC9WsUrT3xW5u8byY6HiR06H13f7VqC6J0ZpprpnOJ2+Mx/xaWb1N+3Fyjon/AMFGZ/UFTTdDyq0XuLnCOKCFvKWZ532YxvtPQn2AAEkgAkSayc5A6nzVvMvcJIGvfWoN67Mga7Zzh+eRzS7f2t7sfirKmmMprq6I85O+xZ11eXU572Y1FnZC6bIHC1SelTHcXPI/w5nNJ3/yA3b7T4qPOBD2gPyuded9+Xnq20//ANZQpNFHKLkf0zl7tnn4r6mxbpjKKVczvZ9h9UYufGZl2Sy2OnAEtO9lrc0MgB3HJjpSD1+0L8W+znCX8C7B2hkbOFdCKxxsuVtOrGIAAR92ZePEAAcdtuikdUaqxejMQcnmLXkdETQ1zL3b3+vLI2KMbNBPV72jfbYb7nYdUqaqxd7UuQ0/Ba55fHwQ2bNfu3ju45S8Ru5EcTuY39ASRt123Ccpv788ZToW88sodOzoPFXMNLiLEmUnxMtc1JKEmXtugfCW8TGYzLxLC31eO223Rd30dj9557/jt3/9ylF08PmqGocbDkMZcgyFCcExWazw+OQAkEtcOhG4PUJym/vzxlOrt7sOv6Ox+889/wAdu/8A7l+m4Mx8TFls5G5p3BOZtP8A+TpCD4KSXTzOXqafw97KZCXyehRgks2JeJdwjY0uc7YAk7AE7AEpym9vzxk1dvdh3cdqPUGn3Ay2Xaioj60U7WR2mj/Ae0NY79DwN/a9XqC/FqbAyT4q86DyiJ7IrTIwXwP2I3LHjo5p8WuHQjYjxCzvF5OtmsZUyFOTvqduFk8MnEt5sc0OadiARuCOhG658JkTprVVaQO4UMtIK1mP2d/sBDL9m5De7P27x/wAs6atdsmPxfPu+nnKuxOGp0dO2u2O0nSo24b87pcllWU4qT8hccHSysYeW5a0BjXOd6zuDWgnbp0AE0iLSpxERAREQEREBERAREQEREBERAREQEREBZ72ifux0v8Aye7/ANhaEs97RP3Y6X/k93/sKf7a/wDGr9suLG+rXPdLhREXlnzwREQEREBFXM1r7D4DWGnNMW5ZG5fUAsmjE2MlrhBGHylzvBuwI8fHdWNTlkmYmMpnrERFCHDhf7pOF/kF3/qrrTlmOF/uk4X+QXf+qutOXprXq9r3T+6p730Z6pR8fnLp5maSviL0sO5lZA9zNv4QaSFlOlGMi0vh2R7d22nCG7DYbcAthc0OaWuAII2IPtWQ4Wo7CtsYOUuMuLk8naX+L4fGF2/t3YWgn+EHDxBW/pszEdUxPz8/F6fAVRFVUKD9IDUWUw2n9N47F5GTCv1BqCnhrGUg272rDLzL3RkghrzwDA4joXg+Oyg+0HBV+zfRsOIrZzWmYvagykFKhCzOuFp05a53AWZN3RRlrHuedzsG+r9i1bVOlcRrbBWsNncfDk8ZaaGy1p27tdsdwftBBAII2IIBCqUXYDoSLB2MT5mlkqTzxWnPlyFmScSxgiN7Z3SGRhaHOALXDYEj2lcqzqoqmZmGCZLK6hb2UdoGntRWZ7EuB1bhYYPK8gb8sMUlmlL3brDmMdIAXnZzm7jfY77LZtKHb6SvaCPacFiCP9+2pyp2F6FpYfOYqLT8Xm/OMjZkYJJpXtsmMkte7k4nvNzuZB65IBJJA27GQ7MsfXuVM1ga1SjqnH0G4yjkrwmsNbXBH4OVjZWGYbb7FztwTvv47ywpt1UzE+ev6rXkaTMlj7NSSSaJliJ0TpK8ropGhwIJY9pDmuG/RwIIPULyjoB1zQX0S9OX8HmMlSu5+1Rxs96xdknZjo5bhhfLCyQlkRDXn6oA5EE9QF6DxWP7RI8jXdks/pixQDwZ4quDsRSvZ7Q17rjg0/nLT+hcOP7ENEYylnKVfBRihmg4XqMk8slZ4c4uPGJzyyP1iT6gb16qGVVM1znGzpYj2n6p1B2G5TVODwGpMrkq82mY8nHNnLTr0uNnN+Kq6Zr5NzxLJnP4u3G8J2AG4Xc7Sqd7s0u5TTNTUmb1DjM9ovN2LdfNXnXHwSwQt4Ttc7qwP7x7S0bN3A2A2Wz6d7GdGaWoZenRwkb4ctF3F83Zpbb7MWxaI3vmc9xYASA3fYbnYL5pPsX0Zol15+JwjGSXa/kc8lueW091f+8h0z3lsfX6g2b+ZTmw1VU+ej/13uy0g9mWkSDuDh6fUf5li7+rXmPBvkZ/bI5oJI/8tszC3/TuAvuktJYrQunqmDwdXyLFVA4QV+9fIIw5xcQC8k7buOw32A2A2AAXdNI57UGJxLNy3vm3rJA6Nhhe1wBP+FJ3bdvaOXsBW/D7LtM9k58NrZXOhamauxrCIiweYEREBERAREQEREBERAREQEREBERAREQFnvaJ+7HS/wDJ7v8A2FoSz3tE/djpf+T3f+wp/tr/AMav2y4sb6tc90uFEReWfPBeZ/pL6w1da7VtG6C08My2lkKVjIWI9P5KDG3bbmEhsbLExAaG7ci1vUg/m3HphVHtE7JtJdrFKrV1XhYctHVeZK73PfFLC47b8JI3Ne3fYbgHrsN/ALZbqimrOXRh7lNu5FVcZx59zzFm7varhuz7SeG1Jlc7pyW72iUsTRyIykE2RfjpmStcyaWBzmSOa7fq4dS0EjoFJ5/tA1T2IS9tmGx2eymo4cHh6OTxU2dn8rsVJJz3ch5uG7mtJ5hrtwOO3tO+/wBbsS0VT05p/Aw4RsWJwOSjy+OrtsTDuLbHOc2Xlz5PPJ7iQ4kHfqCpOXs101Yz2dzM2JisZDOU2Y/Ivme97LNdoIEboySzbZxHQDffrut2tp6485uzlVuemnZ7u+J7Z6s+LzVhtEy6W+kD2DX59aZzWc2XoZazJYy13yiFjvImuLq42/Bsdz+qCRs1v59/Xay/Rv0ZuzXs/wBSUM/p/TLcdlqPe+T2G3LD+77xpa8cXSFpBDiACNhudtitQWu5XFcxk5sTdpuzTo9UZbYy65nq94iItLkcOF/uk4X+QXf+qutOWY4X+6Thf5Bd/wCqutOXprXq9r3T+6p730Z6pR8fnIq3q3SRzfd3qL462YrtLI5ZAe7lZvuYpNuvEnqHDq09RuC5rrIi2U1TTOcLWmqaJ0qelj8+dhxtptTLsfhbjjxbHdIa2Q/4uTfi/wD0Hf7QPBSEcrJmB0b2vafa07haZPXitQvimjZNE8bOZI0Oa4fnBVfm7NdIWDvLpXCSHffd+OhPX/dWeVmrtjx+n/VpTj5y/FSqu6bqzfsWaL/JDA/8Mh/VT9izRf5IYH/hkP6qaFnenhH8mXL43VZ3TdWb9izRf5IYH/hkP6qfsWaL/JDA/wDDIf1U0LO9PCP5HL43VZ3X4msRV28pZGRt+17gArT+xZov8kMD/wAMh/VXNX7OdJ1HNdBpfDQuadwY8fE0g/b0b+YJoWd6eEfU5fG6oVHLHUEpgwEQy8u5aZ4nftWI/wCMl6gfobyd/grRNLaXi03Wlc6QWshZIfatlnHvHAbANbueLG9eLdztuSSXOc4zLGNjY1jGhrWjYNA2AH2L9JNVMRo0RlHjLhvYiu9snZAiItTlEREBERAREQEREBERAREQEREBERAREQFnvaJ+7HS/8nu/9haEs37TbkFLVml5LE8dePuLo5yvDRv+B6blZREzFURu1ftlx4yM8PciOyRFHekWK950/iGfNPSLFe86fxDPmvNam5uzwfPtCvslIoo70ixXvOn8Qz5p6RYr3nT+IZ801NzdngaFfZKRRR3pFivedP4hnzT0ixXvOn8Qz5pqbm7PA0K+yUiijvSLFe86fxDPmnpFivedP4hnzTU3N2eBoV9kpFFHekWK950/iGfNPSLFe86fxDPmmpubs8DQr7JdvC/3ScL/ACC7/wBVdacso01kql/tJw4q2obJbj7nLupA7b1oPHYrV16K3E02LUTHVP7qnu/RsTGEoie/5yIiKVkIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLrXcZTyQYLdSC0GblonjD+P6NwiKYmYnOB1PRbC+6KHwzPknothfdFD4ZnyRFnrK96U5yei2F90UPhmfJPRbC+6KHwzPkiJrK96TOT0Wwvuih8Mz5J6LYX3RQ+GZ8kRNZXvSZyei2F90UPhmfJPRbC+6KHwzPkiJrK96TOT0Wwvuih8Mz5J6LYX3RQ+GZ8kRNZXvSZy56eEx2PlMtWhVrSkcecMLWO2+zcBd1EWEzNW2UP/2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化图\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(\n",
    "            graph.get_graph(xray=True).draw_mermaid_png()\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error generating graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9496a",
   "metadata": {},
   "source": [
    "\n",
    "### 9. 执行工作流\n",
    "\n",
    "接下来我们将执行多智能体构建的工作流，最终生成一些统计图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3322cf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-12T08:11:15.260641Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Obtain the GDP of the United States from 2000 to 2020, and then plot a line chart with Python. End the task after generating the chart。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Researcher\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_MgWjE1PI7uMrzjivloaAS9lU)\n",
      " Call ID: call_MgWjE1PI7uMrzjivloaAS9lU\n",
      "  Args:\n",
      "    query: United States GDP data from 2000 to 2020\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.multpl.com/us-gdp-inflation-adjusted/table/by-year\", \"content\": \"US Real GDP table by year, historic, and current data. Current US Real GDP is 23.22 trillion. S&P 500 PE Ratio; Shiller PE Ratio; ... 2020 20.77 trillion Dec 31, 2019 20.99 trillion Dec 31, 2018 20.30 trillion ... 2000 14.23 trillion Dec 31, 1999 13.83 trillion Dec 31, 1998 13.19 trillion\"}, {\"url\": \"https://www.multpl.com/us-gdp/table/by-year\", \"content\": \"US GDP by Year - Multpl S&P 500 PE Ratio US GDP by Year | Jun 30, 2024 | \\u2002 29.02 trillion | | Dec 31, 2023 | \\u2002 28.30 trillion | | Dec 31, 2022 | \\u2002 26.73 trillion | | Dec 31, 2021 | \\u2002 24.78 trillion | | Dec 31, 2020 | \\u2002 22.07 trillion | | Dec 31, 2019 | \\u2002 21.93 trillion | | Dec 31, 2018 | \\u2002 20.92 trillion | | Dec 31, 2017 | \\u2002 20.04 trillion | | Dec 31, 2016 | \\u2002 19.09 trillion | | Dec 31, 2015 | \\u2002 18.44 trillion | | Dec 31, 2014 | \\u2002 17.91 trillion | | Dec 31, 2013 | \\u2002 17.19 trillion | US Real GDP US Real GDP Growth Rate\"}, {\"url\": \"https://www.macrotrends.net/global-metrics/countries/USA/united-states/gdp-growth-rate\", \"content\": \"U.S. GDP Growth Rate 1961-2024 | MacroTrends U.S. GDP Growth Rate 1961-2024 GDP Growth Rate Annual percentage growth rate of GDP at market prices based on constant local currency. U.S. gdp growth rate for 2023 was 2.54%, a 0.61% increase from 2022. U.S. gdp growth rate for 2022 was 1.94%, a 3.86% decline from 2021. U.S. gdp growth rate for 2021 was 5.80%, a 8.01% increase from 2020. U.S. gdp growth rate for 2020 was -2.21%, a 4.68% decline from 2019. | Country Name | GDP Growth (%) | | U.S. GDP Growth Rate - Historical Data | | U.S. GDP Growth Rate 1961-2024 |  | | U.S. GDP Growth Rate 1961-2024 |  |\"}, {\"url\": \"https://fred.stlouisfed.org/series/GDP/\", \"content\": \"RELEASE TABLES\\nRELATED DATA AND CONTENT\\nData Suggestions Based On Your Search\\nContent Suggestions\\nOther Formats\\nRelated Categories\\nReleases\\nTags\\nSERVICES\\nRESEARCH\\nTOOLS\\nABOUT\\nOUR SITES\\nNeed Help?\\nSubscribe to the FRED newsletter\\nFollow us NOTES\\nSource:\\nU.S. Bureau of Economic Analysis\\nRelease:\\nGross Domestic Product\\nUnits:\\nBillions of Dollars,\\u00a0Seasonally Adjusted Annual Rate\\nFrequency:\\nQuarterly\\nBEA Account Code: A191RCGross domestic product (GDP), the featured measure of U.S. output, is the market value of the goods and services produced by labor and property located in the United States. U.S. Bureau of Economic Analysis,\\nGross Domestic Product [GDP],\\nretrieved from FRED,\\nFederal Reserve Bank of St. Louis;\\nhttps://fred.stlouisfed.org/series/GDP,\\nJanuary 20, 2024.\\n Gross Domestic Product (GDP)\\nObservation:\\nUnits:\\nFrequency:\\nData in this graph are copyrighted. Federal Reserve Economic Data: Your trusted data source since 1991\\nExplore resources provided by the Research Division at the Federal Reserve Bank of St. Louis.\\n\"}, {\"url\": \"https://www.macrotrends.net/global-metrics/countries/USA/united-states/gdp-gross-domestic-product\", \"content\": \"| 2023 | $27,360.94B | $81,695 | 2.54% | | 2022 | $25,744.11B | $77,247 | 1.94% | | 2021 | $23,594.03B | $71,056 | 5.80% | | 2020 | $21,322.95B | $64,317 | -2.21% | | 2019 | $21,521.40B | $65,548 | 2.47% | | 2018 | $20,656.52B | $63,201 | 2.97% | | 2017 | $19,612.10B | $60,322 | 2.46% | | 2016 | $18,804.91B | $58,207 | 1.82% | | 2015 | $18,295.02B | $57,040 | 2.95% | | 2014 | $17,608.14B | $55,304 | 2.52% | | 2013 | $16,880.68B | $53,410 | 2.12% | | 2012 | $16,253.97B | $51,784 | 2.29% | | 2011 | $15,599.73B | $50,066 | 1.56% |\"}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "{'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[2].role', 'code': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      2\u001b[0m     {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[0;32m     17\u001b[0m         event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()  \u001b[38;5;66;03m# 打印消息内容\u001b[39;00m\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1073\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1643\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1641\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1648\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langgraph\\pregel\\retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\runnables\\base.py:2393\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2393\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langgraph\\utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36magent_node\u001b[1;34m(state, agent, name)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_node\u001b[39m(state, agent, name):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 调用智能体，获取结果\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 将智能体的输出转换为适合追加到全局状态的格式\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, ToolMessage):\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\runnables\\base.py:2393\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2393\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\runnables\\base.py:4427\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4422\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4423\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4424\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4425\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   4428\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4429\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4430\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4431\u001b[0m     )\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    169\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    171\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    172\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    173\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    174\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    175\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    176\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    177\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    179\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    460\u001b[0m ]\n\u001b[0;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 446\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    447\u001b[0m                 m,\n\u001b[0;32m    448\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    449\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    451\u001b[0m             )\n\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    672\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    673\u001b[0m         )\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:523\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    522\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\data\\conda\\envs\\openai-quickstart\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:548\u001b[0m, in \u001b[0;36mBaseChatOpenAI._create_chat_result\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# Sometimes the AI Model calling will get error, we should raise it.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# Otherwise, the next code 'choices.extend(response[\"choices\"])'\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# will throw a \"TypeError: 'NoneType' object is not iterable\" error\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# to mask the true error. Because 'response[\"choices\"]' is None.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m     message \u001b[38;5;241m=\u001b[39m _convert_dict_to_message(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[2].role', 'code': None}"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Obtain the GDP of the United States from 2000 to 2020, \"\n",
    "            \"and then plot a line chart with Python. End the task after generating the chart。\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # 设置最大递归限制\n",
    "    {\"recursion_limit\": 20},\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()  # 打印消息内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c04d36fc4388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e1c69-7ee9-4794-9e38-d035cde69021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f39b6-79c7-46a3-b705-8835bc15d0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480064c-3fbe-40ca-bb5a-80403d4b39c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c5551b6-1212-4686-8943-29605b2a783b",
   "metadata": {},
   "source": [
    "### 手动复现 `python_repl` 工具执行的 Python 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd906fa-4005-480c-b272-75ff955e991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Years and corresponding GDP values\n",
    "years = list(range(2000, 2021))\n",
    "gdp_values = [\n",
    "    10.25, 10.58, 10.64, 10.86, 11.19, \n",
    "    11.66, 12.24, 12.54, 12.53, 12.11, \n",
    "    14.58, 15.17, 15.52, 16.16, 16.78, \n",
    "    17.36, 17.75, 18.12, 18.71, 21.43, \n",
    "    21.43\n",
    "]\n",
    "\n",
    "# Plotting the GDP data\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(years, gdp_values, marker='o')\n",
    "plt.title('GDP of the United States (2000 - 2020)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('GDP in Trillions (USD)')\n",
    "plt.xticks(years, rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057fa47-8044-4e63-9dfd-b3ee7dd4d1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d89aecb-4d44-46a2-8700-c6817b1cdf39",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. 使用不同的大模型运行多智能体，对比结果并评选 `gpt-4o` 之下最好的大模型，将所有的大模型和最终结果生成一张表格；\n",
    "2. 将 `Chart_Generator` 替换为其他功能智能体（如 `table_generator`），为其设计提示词，然后运行查看生成结果。\n",
    "3. [**可选**]优化研究智能体 `Researcher` 提示词和路由函数 `route` 跳转逻辑，提升图表生成的成功率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f65c8-53ac-46ae-b9d6-aa5cafa93fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7de09-9232-4383-b10b-382e7a7a6e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac3a66-fa05-464f-955b-f558f179fda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ac070-993e-4917-ad13-1bd274b5b73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7827953b-f16a-4d23-929a-73a8aca40d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341ec25-8f83-4d28-b052-a35cc2aea2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
