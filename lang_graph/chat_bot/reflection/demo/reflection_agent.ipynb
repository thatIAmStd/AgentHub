{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e64d1c",
   "metadata": {},
   "source": [
    "\n",
    "# LangGraph Reflection 机制开发指南\n",
    "\n",
    "本指南详细介绍了如何在 **LangGraph** 中构建基于大语言模型（LLM）的 **Reflection（反思）** 机制。\n",
    "\n",
    "Reflection 是一种重要的模型能力，通过让模型观察其过去的步骤和外部环境反馈，评估自身行为的质量，并不断改进输出。在生成与反思的循环中，模型可以逐步优化内容，从而提升生成质量和用户满意度。\n",
    "\n",
    "Reflection 机制被广泛应用于生成任务中，例如文章写作、内容修改与反馈、以及智能助理等场景。通过引导 LLM 进行自我反思和用户反馈处理，开发者可以让模型在多轮交互中自动调整其生成的内容，达到高效、精准、结构完善的输出。\n",
    "\n",
    "\n",
    "\n",
    "在本指南中，我们会逐步演示如何搭建这一机制，包括从基础的环境配置到生成器和反思器的构建，再到如何使用 LangGraph 状态图实现生成-反思循环的完整流程。无论您是为文章生成、内容评估，还是其他复杂任务设计 LLM 代理，本指南都将为您提供详细的开发思路和实用的代码示例。\n",
    "\n",
    "![reflection](./images/reflection.png)\n",
    "\n",
    "通过本指南，您将学习如何：\n",
    "1. 设置开发环境并安装所需包；\n",
    "2. 定义和生成灵活结构的文章，不局限于传统的五段式；\n",
    "3. 通过反思机制批改生成内容，并提供详细反馈；\n",
    "4. 构建反思与生成的状态循环，使模型持续改进生成内容。\n",
    "\n",
    "本开发指南适合任何希望构建复杂 LLM 任务的开发者，特别是需要实现生成-反思流程、文章批改反馈、或其他高级交互任务的场景。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e06a35-b8fb-4475-ac56-eef76a78e3b2",
   "metadata": {},
   "source": [
    "## 1. 环境设置\n",
    "首先，安装所需的包并设置API密钥："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d045265-8b0b-42e7-9bec-9e18e62a8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langgraph langchain-ollama tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c166149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# 定义一个帮助函数来检查环境变量，如果不存在则提示用户输入\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"请输入您的 {var}\")\n",
    "\n",
    "# 设置 OpenAI 和 Langchain API 密钥\n",
    "# _set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# _set_if_undefined(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec8159-c202-4274-b4cb-eddfa337940a",
   "metadata": {},
   "source": [
    "## 2. LangSmith开发配置\n",
    "LangSmith能够帮助您快速发现问题并提高LangGraph项目的性能。通过LangSmith，您可以使用跟踪数据来调试、测试和监控基于LangGraph构建的LLM应用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c231a35a-8f08-44d1-abda-5d0defd00dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 LangSmith 中添加追踪功能\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Reflection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75943d-3e39-4765-811a-2c9a47cf3722",
   "metadata": {},
   "source": [
    "## 3. 定义写作助手智能体\n",
    "\n",
    "我们定义的这个助手是一个写作助手，旨在为用户生成高质量、结构清晰且引人入胜的文章。它的任务是根据用户的请求撰写内容，无论是短文、长篇、议论文还是其他类型的文章，都能够灵活应对。助手会专注于文章的清晰度、结构和质量，确保输出的内容是精心打磨过的。如果用户对生成的内容有反馈或建议，助手还能够根据这些反馈改进和优化文章，使其更符合用户的期望。这种互动机制保证了写作过程的灵活性和个性化，从而让用户获得更符合需求的成品。\n",
    "\n",
    "\n",
    "### System Prompt 详细解释：\n",
    "1. **\"You are a writing assistant\"**：写作助手的角色设定，让模型明确其任务是帮助用户进行写作。\n",
    "   \n",
    "2. **\"well-crafted, coherent, and engaging articles\"**：描述了文章应该具备的特性，包括“精心撰写的、连贯的和吸引人的”，但没有限制文章的具体结构，可以是不同类型的文章（如叙述文、议论文等）。\n",
    "\n",
    "3. **\"Focus on clarity, structure, and quality\"**：明确了撰写时需要关注的核心要素：清晰度、结构性和质量，确保输出内容优秀。\n",
    "\n",
    "4. **\"revise and improve the writing\"**：模型可以根据用户的反馈进行修改和优化，保持互动的灵活性。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1905a06e-af05-4691-a6ed-014be2cfaf06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:14:34.725926Z",
     "start_time": "2024-12-16T03:14:33.608488Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a writing assistant tasked with creating well-crafted, coherent, and engaging articles based on the user's request.\"\n",
    "            \" Focus on clarity, structure, and quality to produce the best possible piece of writing.\"\n",
    "            \" If the user provides feedback or suggestions, revise and improve the writing to better align with their expectations.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# writer = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2f0cec14-582a-4094-9a5b-9a0a2ae04a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:15:04.571221Z",
     "start_time": "2024-12-16T03:15:04.204148Z"
    }
   },
   "source": [
    "writer = writer_prompt | ChatOllama(\n",
    "    model=\"llama3.1:8b-instruct-q8_0\",\n",
    "    max_tokens=8192,\n",
    "    temperature=1.2,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a374db97-f61e-44d0-9fb7-8be1d3368a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:16:24.057527Z",
     "start_time": "2024-12-16T03:15:40.723317Z"
    }
   },
   "source": [
    "article = \"\"\n",
    "\n",
    "topic = HumanMessage(\n",
    "    content=\"参考鲁迅的风格，改写吴承恩的西游记中任意篇章\"\n",
    ")\n",
    "\n",
    "for chunk in writer.stream({\"messages\": [topic]}):\n",
    "    print(chunk.content, end=\"\")\n",
    "    article += chunk.content"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "题目：《蟒神潇洒》\n",
      "\n",
      "本次改写的篇章为《西游记》中第六回“唐僧被绑出华阳关, 逃脱后又被金蝉子绑住”。鲁迅式的风格通常以幽默、讥诮和尖锐的语言著称，下面是改写后的篇章：\n",
      "\n",
      "---\n",
      "\n",
      "我不曾知道，一只蟒神居然可以有那么多姿势。\n",
      "\n",
      "金蟒出自大海深处，是个无厘头的家伙，喜欢在华山麓游来玩去。听说他擅长打扮成各种各样的装束，令众人看了莫名其妙。\n",
      "\n",
      "那日，唐僧一行人刚到达华阳关边上，大口大口地吞下蟒神变出的两块大饼。大碗呃得呼呼响的唐僧，更显得跟那座山一样胖。\n",
      "\n",
      "金蝉子是个能打擂鼓、跳芭蕾舞、背刺客手法书的人物。他想趁机杀死唐僧，自己做佛教圣人。于是一招手，让一只大蚊子把蟒神的头绑住了。\n",
      "\n",
      "忽然，金蝉又变了一回生，这回他是大虫子模样了。一溜烟地跑得无影无踪。\n",
      "\n",
      "蟒神头上一块绳子还未解开，他就跳下华阳关，没入滔滔黄河中去。他随身带着唐僧，一直到了长江边。金蝉只说“走，去那边吃些青苇吧”便逃窜了。\n",
      "\n",
      "蟒神突然停住，并且睁眼朝唐僧笑着道：“你看我有多么潇洒？”这只蟒神，确实有些了不起。"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "576b8163-56b5-4b49-9dd3-aaf14f1566db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:16:56.147947Z",
     "start_time": "2024-12-16T03:16:56.136406Z"
    }
   },
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 使用Markdown显示优化后的格式\n",
    "display(Markdown(article))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "题目：《蟒神潇洒》\n\n本次改写的篇章为《西游记》中第六回“唐僧被绑出华阳关, 逃脱后又被金蝉子绑住”。鲁迅式的风格通常以幽默、讥诮和尖锐的语言著称，下面是改写后的篇章：\n\n---\n\n我不曾知道，一只蟒神居然可以有那么多姿势。\n\n金蟒出自大海深处，是个无厘头的家伙，喜欢在华山麓游来玩去。听说他擅长打扮成各种各样的装束，令众人看了莫名其妙。\n\n那日，唐僧一行人刚到达华阳关边上，大口大口地吞下蟒神变出的两块大饼。大碗呃得呼呼响的唐僧，更显得跟那座山一样胖。\n\n金蝉子是个能打擂鼓、跳芭蕾舞、背刺客手法书的人物。他想趁机杀死唐僧，自己做佛教圣人。于是一招手，让一只大蚊子把蟒神的头绑住了。\n\n忽然，金蝉又变了一回生，这回他是大虫子模样了。一溜烟地跑得无影无踪。\n\n蟒神头上一块绳子还未解开，他就跳下华阳关，没入滔滔黄河中去。他随身带着唐僧，一直到了长江边。金蝉只说“走，去那边吃些青苇吧”便逃窜了。\n\n蟒神突然停住，并且睁眼朝唐僧笑着道：“你看我有多么潇洒？”这只蟒神，确实有些了不起。"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "73fa01c1-9074-41ae-810b-450edc7261ea",
   "metadata": {},
   "source": [
    "----------\n",
    "## 4. 定义审阅老师智能体\n",
    "\n",
    "下面我们使用反思机制批改生成的作文，生成一篇作文的反馈和建议。\n",
    "\n",
    "模型扮演“老师”角色，针对用户提交的作文进行打分、批改和提供改进建议。\n",
    "\n",
    "### System Prompt 详细解释：\n",
    "\n",
    "- **\"You are a teacher grading an essay submission.\"**\n",
    "  - 模型被设定为一个老师角色，专门负责为用户提交的作文进行批改。这一角色定位帮助模型理解其任务是提供具有建设性的反馈和评价。\n",
    "  \n",
    "- **\"Generate critique and recommendations for the user's submission.\"**\n",
    "  - 模型需要生成作文的批评与建议。它不只是评估作文的好坏，还需要指出需要改进的地方，并提出具体的建议。\n",
    "\n",
    "- **\"Provide detailed recommendations, including requests for length, depth, style, etc.\"**\n",
    "  - 这一部分进一步明确了反馈的细节，要求模型给出细致的建议。这包括：\n",
    "    - **Length（长度）**：文章的字数是否合适，是否需要扩展或删减。\n",
    "    - **Depth（深度）**：是否需要更深入的分析或讨论。\n",
    "    - **Style（风格）**：文章的写作风格是否合适，是否符合目标读者或主题的需求。\n",
    "  \n",
    "这一设定确保了模型不仅给出基本反馈，还可以根据文章的具体问题提出具体的改进意见，帮助用户更好地提升其写作。"
   ]
  },
  {
   "cell_type": "code",
   "id": "7001a65a-88ca-4ab7-bc66-fa1df870f99e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:17:05.877731Z",
     "start_time": "2024-12-16T03:17:05.495135Z"
    }
   },
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a teacher grading an article submission. writer critique and recommendations for the user's submission.\"\n",
    "            \" Provide detailed recommendations, including requests for length, depth, style, etc.\",\n",
    "\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflect = reflection_prompt | ChatOllama(\n",
    "    model=\"llama3.1:8b-instruct-q8_0\",\n",
    "    max_tokens=8192,\n",
    "    temperature=0.2,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ef0c878a-f333-4fb6-b879-e7636d1087ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:20:44.768374Z",
     "start_time": "2024-12-16T03:19:37.614700Z"
    }
   },
   "source": [
    "reflection = \"\"\n",
    "\n",
    "# 将主题（topic）和生成的文章（article）作为输入发送给反思智能体\n",
    "for chunk in reflect.stream({\"messages\": [topic, HumanMessage(content=article)]}):\n",
    "    print(chunk.content, end=\"\")\n",
    "    reflection += chunk.content"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "很好！你的改写作品《蟒神潇洒》展现出鲁迅式的幽默和讥诮风格。以下是我的反馈和建议：\n",
      "\n",
      "**强点：**\n",
      "\n",
      "1. 你成功地捕捉到了鲁迅的幽默和讥诮风格，特别是在对金蝉子和蟒神的描写中。\n",
      "2. 你使用了生动的语言和形象，比如“无厘头的家伙”、“莫名其妙”、“大碗呃得呼呼响”等，这使读者能够更好地想象场景。\n",
      "3. 你在故事中加入了许多有趣的细节，例如蟒神的多种姿势和金蝉子的变形能力。\n",
      "\n",
      "**弱点：**\n",
      "\n",
      "1. **篇章长度**: 你的改写作品略短于原版第六回的内容。考虑到鲁迅的风格通常较长篇幅，你可以尝试增加一些细节或场景来丰富故事。\n",
      "2. **深度和层次感**: 虽然你成功地捕捉到了幽默和讥诮，但有些地方可能需要更多的深度和层次感。例如，金蝉子的动机和心理活动可以更详细地描述，以使读者更好地理解他的行为。\n",
      "3. **语言风格**: 虽然你使用了生动的语言，但在某些地方可能需要更加精确和准确的表达。例如，“莫名其妙”这个词可能不太适合鲁迅式的幽默风格，你可以尝试用更有创意的语言来描述金蝉子的行为。\n",
      "4. **结尾**: 你的改写作品在结尾处略显突然，蟒神的潇洒表现似乎没有得到充分的体现。你可以考虑增加一些细节或场景来使读者更好地理解蟒神的潇洒之处。\n",
      "\n",
      "**建议：**\n",
      "\n",
      "1. **增加篇章长度**: 尝试增加一些细节或场景来丰富故事，例如金蝉子的动机和心理活动、蟒神的多种姿势等。\n",
      "2. **深化人物性格**: 尽管你成功地捕捉到了幽默和讥诮，但有些地方可能需要更多的深度和层次感。例如，金蝉子的动机和心理活动可以更详细地描述，以使读者更好地理解他的行为。\n",
      "3. **语言风格**: 尝试使用更加精确和准确的表达来描述金蝉子的行为和蟒神的多种姿势。\n",
      "4. **结尾**: 考虑增加一些细节或场景来使读者更好地理解蟒神的潇洒之处。\n",
      "\n",
      "总体来说，你的改写作品展现出鲁迅式的幽默和讥诮风格，值得继续努力！"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3c616014-c9c9-4d46-be9f-87485ee750eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:21:22.131848Z",
     "start_time": "2024-12-16T03:21:22.126510Z"
    }
   },
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 使用Markdown显示优化后的格式\n",
    "display(Markdown(reflection))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "很好！你的改写作品《蟒神潇洒》展现出鲁迅式的幽默和讥诮风格。以下是我的反馈和建议：\n\n**强点：**\n\n1. 你成功地捕捉到了鲁迅的幽默和讥诮风格，特别是在对金蝉子和蟒神的描写中。\n2. 你使用了生动的语言和形象，比如“无厘头的家伙”、“莫名其妙”、“大碗呃得呼呼响”等，这使读者能够更好地想象场景。\n3. 你在故事中加入了许多有趣的细节，例如蟒神的多种姿势和金蝉子的变形能力。\n\n**弱点：**\n\n1. **篇章长度**: 你的改写作品略短于原版第六回的内容。考虑到鲁迅的风格通常较长篇幅，你可以尝试增加一些细节或场景来丰富故事。\n2. **深度和层次感**: 虽然你成功地捕捉到了幽默和讥诮，但有些地方可能需要更多的深度和层次感。例如，金蝉子的动机和心理活动可以更详细地描述，以使读者更好地理解他的行为。\n3. **语言风格**: 虽然你使用了生动的语言，但在某些地方可能需要更加精确和准确的表达。例如，“莫名其妙”这个词可能不太适合鲁迅式的幽默风格，你可以尝试用更有创意的语言来描述金蝉子的行为。\n4. **结尾**: 你的改写作品在结尾处略显突然，蟒神的潇洒表现似乎没有得到充分的体现。你可以考虑增加一些细节或场景来使读者更好地理解蟒神的潇洒之处。\n\n**建议：**\n\n1. **增加篇章长度**: 尝试增加一些细节或场景来丰富故事，例如金蝉子的动机和心理活动、蟒神的多种姿势等。\n2. **深化人物性格**: 尽管你成功地捕捉到了幽默和讥诮，但有些地方可能需要更多的深度和层次感。例如，金蝉子的动机和心理活动可以更详细地描述，以使读者更好地理解他的行为。\n3. **语言风格**: 尝试使用更加精确和准确的表达来描述金蝉子的行为和蟒神的多种姿势。\n4. **结尾**: 考虑增加一些细节或场景来使读者更好地理解蟒神的潇洒之处。\n\n总体来说，你的改写作品展现出鲁迅式的幽默和讥诮风格，值得继续努力！"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "50ad3e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:45:04.830763Z",
     "start_time": "2024-12-16T03:45:04.815759Z"
    }
   },
   "source": [
    "from typing import Annotated  # 用于类型注解\n",
    "from langgraph.graph import END, StateGraph, START  # 导入状态图的相关常量和类\n",
    "from langgraph.graph.message import add_messages  # 用于在状态中处理消息\n",
    "from langgraph.checkpoint.memory import MemorySaver  # 内存保存机制，用于保存检查点\n",
    "from typing_extensions import TypedDict  # 用于定义带有键值对的字典类型\n",
    "\n",
    "# 定义状态类，使用TypedDict以保存消息\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # 使用注解确保消息列表使用add_messages方法处理\n",
    "\n",
    "# 异步生成节点函数：生成内容（如作文）\n",
    "# 输入状态，输出包含新生成消息的状态\n",
    "async def generation_node(state: State) -> State:\n",
    "    # 调用生成器(writer)，并将消息存储到新的状态中返回\n",
    "    return {\"messages\": [await writer.ainvoke(state['messages'])]}\n",
    "\n",
    "# 异步反思节点函数：对生成的内容进行反思和反馈\n",
    "# 输入状态，输出带有反思反馈的状态\n",
    "async def reflection_node(state: State) -> State:\n",
    "    # 创建一个消息类型映射，ai消息映射为HumanMessage，human消息映射为AIMessage\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    \n",
    "    # 处理消息，保持用户的原始请求（第一个消息），转换其余消息的类型\n",
    "    translated = [state['messages'][0]] + [\n",
    "        cls_map[msg.type](content=msg.content) for msg in state['messages'][1:]\n",
    "    ]\n",
    "    \n",
    "    # 调用反思器(reflect)，将转换后的消息传入，获取反思结果\n",
    "    res = await reflect.ainvoke(translated)\n",
    "    \n",
    "    # 返回新的状态，其中包含反思后的消息\n",
    "    return {\"messages\": [HumanMessage(content=res.content)]}\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ef78c4fb-2db3-45c0-9784-b73de4e7ab7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:45:09.661694Z",
     "start_time": "2024-12-16T03:45:09.651695Z"
    }
   },
   "source": [
    "MAX_ROUND = 6\n",
    "\n",
    "# 定义条件函数，决定是否继续反思过程\n",
    "# 如果消息数量超过6条，则终止流程\n",
    "def should_continue(state: State):\n",
    "    if len(state[\"messages\"]) > MAX_ROUND:\n",
    "        return END  # 达到条件时，流程结束\n",
    "    return \"reflect\"  # 否则继续进入反思节点"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "2e188e5e-2327-4c78-927e-5f778fdca91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:45:11.108231Z",
     "start_time": "2024-12-16T03:45:11.094235Z"
    }
   },
   "source": [
    "# 创建状态图，传入初始状态结构\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# 在状态图中添加\"writer\"节点，节点负责生成内容\n",
    "builder.add_node(\"writer\", generation_node)\n",
    "\n",
    "# 在状态图中添加\"reflect\"节点，节点负责生成反思反馈\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "\n",
    "# 定义起始状态到\"writer\"节点的边，从起点开始调用生成器\n",
    "builder.add_edge(START, \"writer\")\n",
    "\n",
    "\n",
    "# 在\"writer\"节点和\"reflect\"节点之间添加条件边\n",
    "# 判断是否需要继续反思，或者结束\n",
    "builder.add_conditional_edges(\"writer\", should_continue)\n",
    "\n",
    "# 添加从\"reflect\"节点回到\"writer\"节点的边，进行反复的生成-反思循环\n",
    "builder.add_edge(\"reflect\", \"writer\")\n",
    "\n",
    "# 创建内存保存机制，允许在流程中保存中间状态和检查点\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译状态图，使用检查点机制\n",
    "graph = builder.compile(checkpointer=memory)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce358b-9b0d-4297-94e2-6ed8ab7e4dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "b28225cf-55bc-4cc3-8fc7-45064d224782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:45:16.103606Z",
     "start_time": "2024-12-16T03:45:14.731784Z"
    }
   },
   "source": [
    "# 可视化图\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(\n",
    "            graph.get_graph(xray=True).draw_mermaid_png()\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error generating graph: {e}\")"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "a16cf4e0-abc5-4956-990c-09f78254b227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:45:22.817824Z",
     "start_time": "2024-12-16T03:45:22.800406Z"
    }
   },
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 定义装饰器，记录函数调用次数\n",
    "def track_steps(func):\n",
    "    step_counter = {'count': 0}  # 用于记录调用次数\n",
    "    \n",
    "    def wrapper(event, *args, **kwargs):\n",
    "        # 增加调用次数\n",
    "        step_counter['count'] += 1\n",
    "        # 在函数调用之前打印 step\n",
    "        display(Markdown(f\"## Round {step_counter['count']}\"))\n",
    "        # 调用原始函数\n",
    "        return func(event, *args, **kwargs)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# 使用装饰器装饰 pretty_print_event_markdown 函数\n",
    "@track_steps\n",
    "def pretty_print_event_markdown(event):\n",
    "    # 如果是生成写作部分\n",
    "    if 'writer' in event:\n",
    "        generate_md = \"#### 写作生成:\\n\"\n",
    "        for message in event['writer']['messages']:\n",
    "            generate_md += f\"- {message.content}\\n\"\n",
    "        display(Markdown(generate_md))\n",
    "    \n",
    "    # 如果是反思评论部分\n",
    "    if 'reflect' in event:\n",
    "        reflect_md = \"#### 评论反思:\\n\"\n",
    "        for message in event['reflect']['messages']:\n",
    "            reflect_md += f\"- {message.content}\\n\"\n",
    "        display(Markdown(reflect_md))"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64544540-9594-4812-a66a-c019284bdf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "2954d151-db4c-46cf-97db-1ce5bf9fc7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:48:36.389799Z",
     "start_time": "2024-12-16T03:45:25.861017Z"
    }
   },
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"参考西游记唐僧的说话风格，写一篇奉劝年轻人努力工作的文章\")\n",
    "    ],\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "async for event in graph.astream(inputs, config):\n",
    "    pretty_print_event_markdown(event)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Round 1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "#### 写作生成:\n- 小子呀，小女孩呀！你以为只是混个度假生活就能长久吗？世道苦海中，我不问你是做何种事业，只要你认真地把事做好，就算了！\n\n你看看，人生短暂，光阴易逝。不要认为自己年轻就会得享福，享福的路走在汗水中！没有苦劳付出，所谓幸福只是一片空虚！\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Round 2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "#### 评论反思:\n- **总体评分：7/10**\n\n这篇文章有很好的开头和情感表达，但仍需要进一步改进以使其更具说服力和深度。以下是我的建议：\n\n**长度和结构**: 文章太短了，仅有一段话就结束了。建议增加到至少两页的长度，以便能够全面阐述主题并提供更多例子或证据。\n\n**风格和语气**: 文章采用了一种很好的口头语气，但仍需要进一步发展以使其更具说服力。例如，你可以使用比喻、寓言或故事来加深读者的理解和记忆。\n\n**内容的具体化**: 文章太过笼统，没有提供具体的例子或证据来支持你的论点。建议增加一些具体的事例，例如成功人士的故事，或研究结果来证明努力工作的重要性。\n\n**语言和表达**: 语言简单明了，但仍需要进一步改进以使其更具说服力。例如，你可以使用比喻、修辞手法或其他文学技巧来加深读者的理解和记忆。\n\n具体建议：\n\n1. **增加长度和结构**: 增加到至少两页的长度，以便能够全面阐述主题并提供更多例子或证据。\n2. **发展口头语气**: 使用比喻、寓言或故事来加深读者的理解和记忆。\n3. **具体化内容**: 提供具体的事例，例如成功人士的故事，或研究结果来证明努力工作的重要性。\n4. **语言和表达**: 使用比喻、修辞手法或其他文学技巧来加深读者的理解和记忆。\n\n**修改建议**\n\n* 在开头增加一个引言，以便吸引读者并设置主题。\n* 在第二段中提供具体的事例，例如成功人士的故事，或研究结果来证明努力工作的重要性。\n* 在第三段中使用比喻、寓言或故事来加深读者的理解和记忆。\n* 在结尾增加一个总结，以便强调主题并留下深刻印象。\n\n**修改示例**\n\n开头：\n\n小子呀，小女孩呀！你以为只是混个度假生活就能长久吗？世道苦海中，我不问你是做何种事业，只要你认真地把事做好，就算了！\n\n第二段：\n\n你看看，人生短暂，光阴易逝。不要认为自己年轻就会得享福，享福的路走在汗水中！没有苦劳付出，所谓幸福只是一片空虚！比如说，著名企业家李嘉诚，他从小就开始努力工作，通过辛勤的劳动和不断的学习，最终成为亿万富翁。他的成功故事告诉我们，努力工作是通往成功的必经之路。\n\n第三段：\n\n但是，我们也不能忽视失败的可能性。每个人都可能遇到挫折和困难，但关键在于如何面对这些挑战。像李嘉诚一样，通过不断学习和自我改进来克服困难，才能真正实现成功。\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Round 3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "#### 写作生成:\n- **修改后文章**\n\n小子呀，小女孩呀！你以为只是混个度假生活就能长久吗？世道苦海中，我不问你是做何种事业，只要你认真地把事做好，就算了！\n\n你看看，人生短暂，光阴易逝。不要认为自己年轻就会得享福，享福的路走在汗水中！没有苦劳付出，所谓幸福只是一片空虚！比如说，著名企业家李嘉诚，他从小就开始努力工作，通过辛勤的劳动和不断的学习，最终成为亿万富翁。他的成功故事告诉我们，努力工作是通往成功的必经之路。\n\n但是，我们也不能忽视失败的可能性。每个人都可能遇到挫折和困难，但关键在于如何面对这些挑战。像李嘉诚一样，通过不断学习和自我改进来克服困难，才能真正实现成功。记得那句古话： \"行百里者半九十\"，意思是说，走完一百里路的人，其实已经走了90里了。如果你想实现你的目标，就必须愿意付出汗水和努力工作。\n\n然而，你也要知道，不一定所有的努力都会带来成功。有时候，我们会遇到不可避免的困难或障碍。但是，这并不意味着就放弃努力了。我们应该记住，失败是成功之母，只有通过失败，才能更好地认识自己，学会更加有效的工作方法和策略。\n\n所以，小子呀，小女孩呀！如果你想实现你的目标，就必须愿意付出汗水和努力工作。没有汗水就不会有成功的果实。你看看周围的人，他们都有自己的故事，都有他们自己的努力过程。也许你不一定能像李嘉诚一样成就伟大的事业，但是只要你肯努力，肯学习，那么你一定会达到自己想成为的人。\n\n总而言之，努力工作是通往成功的必经之路。无论你是做什么事业，只要你认真地把事做好，就算了！所以，小子呀，小女孩呀！只要你肯努力，一定会有自己的成功故事！\n\n**修改后内容**\n\n1. 增加了长度和结构，详细阐述主题并提供更多例子或证据。\n2. 开发了口头语气，使用比喻、寓言或故事来加深读者的理解和记忆。\n3.具体化了内容，提供了成功人士的故事，或研究结果来证明努力工作的重要性。\n4. 使用了比喻、修辞手法或其他文学技巧来加深读者的理解和记忆。\n\n以上修改后文章，希望更能够符合你的要求。\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_ollama\\chat_models.py:586\u001B[0m, in \u001B[0;36mChatOllama._achat_stream_with_aggregation\u001B[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    585\u001B[0m final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 586\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m stream_resp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_acreate_chat_stream(messages, stop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stream_resp, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_ollama\\chat_models.py:487\u001B[0m, in \u001B[0;36mChatOllama._acreate_chat_stream\u001B[1;34m(self, messages, stop, **kwargs)\u001B[0m\n\u001B[0;32m    486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 487\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_async_client\u001B[38;5;241m.\u001B[39mchat(\n\u001B[0;32m    488\u001B[0m         model\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    489\u001B[0m         messages\u001B[38;5;241m=\u001B[39mollama_messages,\n\u001B[0;32m    490\u001B[0m         stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    491\u001B[0m         options\u001B[38;5;241m=\u001B[39mOptions(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptions\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m    492\u001B[0m         keep_alive\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeep_alive\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    493\u001B[0m         \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    494\u001B[0m     ):  \u001B[38;5;66;03m# type:ignore\u001B[39;00m\n\u001B[0;32m    495\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m part\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ollama\\_client.py:671\u001B[0m, in \u001B[0;36mAsyncClient._request.<locals>.inner\u001B[1;34m()\u001B[0m\n\u001B[0;32m    669\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mtext, e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mstatus_code) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 671\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39maiter_lines():\n\u001B[0;32m    672\u001B[0m   part \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(line)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_models.py:965\u001B[0m, in \u001B[0;36mResponse.aiter_lines\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[1;32m--> 965\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maiter_text():\n\u001B[0;32m    966\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m decoder\u001B[38;5;241m.\u001B[39mdecode(text):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_models.py:952\u001B[0m, in \u001B[0;36mResponse.aiter_text\u001B[1;34m(self, chunk_size)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[1;32m--> 952\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m byte_content \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maiter_bytes():\n\u001B[0;32m    953\u001B[0m         text_content \u001B[38;5;241m=\u001B[39m decoder\u001B[38;5;241m.\u001B[39mdecode(byte_content)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_models.py:931\u001B[0m, in \u001B[0;36mResponse.aiter_bytes\u001B[1;34m(self, chunk_size)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[1;32m--> 931\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m raw_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maiter_raw():\n\u001B[0;32m    932\u001B[0m         decoded \u001B[38;5;241m=\u001B[39m decoder\u001B[38;5;241m.\u001B[39mdecode(raw_bytes)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_models.py:989\u001B[0m, in \u001B[0;36mResponse.aiter_raw\u001B[1;34m(self, chunk_size)\u001B[0m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[1;32m--> 989\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m raw_stream_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream:\n\u001B[0;32m    990\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_bytes_downloaded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(raw_stream_bytes)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:150\u001B[0m, in \u001B[0;36mBoundAsyncStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__aiter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mAsyncIterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[0;32m    151\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py:257\u001B[0m, in \u001B[0;36mAsyncResponseStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 257\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_httpcore_stream:\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m part\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py:367\u001B[0m, in \u001B[0;36mPoolByteStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maclose()\n\u001B[1;32m--> 367\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py:363\u001B[0m, in \u001B[0;36mPoolByteStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 363\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m part\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py:349\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maclose()\n\u001B[1;32m--> 349\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py:341\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__aiter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_body\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request, kwargs):\n\u001B[1;32m--> 341\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39m_receive_response_body(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    342\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py:210\u001B[0m, in \u001B[0;36mAsyncHTTP11Connection._receive_response_body\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 210\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_receive_event(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mData):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py:224\u001B[0m, in \u001B[0;36mAsyncHTTP11Connection._receive_event\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[1;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\u001B[38;5;241m.\u001B[39mread(\n\u001B[0;32m    225\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mREAD_NUM_BYTES, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[0;32m    226\u001B[0m     )\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_backends\\anyio.py:35\u001B[0m, in \u001B[0;36mAnyIOStream.read\u001B[1;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream\u001B[38;5;241m.\u001B[39mreceive(max_bytes\u001B[38;5;241m=\u001B[39mmax_bytes)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m anyio\u001B[38;5;241m.\u001B[39mEndOfStream:  \u001B[38;5;66;03m# pragma: nocover\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anyio\\_backends\\_asyncio.py:1198\u001B[0m, in \u001B[0;36mSocketStream.receive\u001B[1;34m(self, max_bytes)\u001B[0m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transport\u001B[38;5;241m.\u001B[39mresume_reading()\n\u001B[1;32m-> 1198\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_protocol\u001B[38;5;241m.\u001B[39mread_event\u001B[38;5;241m.\u001B[39mwait()\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transport\u001B[38;5;241m.\u001B[39mpause_reading()\n",
      "File \u001B[1;32mD:\\data\\conda\\envs\\AgentHub2\\lib\\asyncio\\locks.py:214\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 214\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m fut\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mCancelledError\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:298\u001B[0m, in \u001B[0;36mBaseChatModel.ainvoke\u001B[1;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[0;32m    297\u001B[0m config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m--> 298\u001B[0m llm_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magenerate_prompt(\n\u001B[0;32m    299\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[0;32m    300\u001B[0m     stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    301\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    302\u001B[0m     tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    303\u001B[0m     metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    304\u001B[0m     run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    305\u001B[0m     run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    306\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    307\u001B[0m )\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(ChatGeneration, llm_result\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:787\u001B[0m, in \u001B[0;36mBaseChatModel.agenerate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    786\u001B[0m prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 787\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magenerate(\n\u001B[0;32m    788\u001B[0m     prompt_messages, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    789\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:713\u001B[0m, in \u001B[0;36mBaseChatModel.agenerate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    703\u001B[0m run_managers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m callback_manager\u001B[38;5;241m.\u001B[39mon_chat_model_start(\n\u001B[0;32m    704\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    705\u001B[0m     messages,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    710\u001B[0m     run_id\u001B[38;5;241m=\u001B[39mrun_id,\n\u001B[0;32m    711\u001B[0m )\n\u001B[1;32m--> 713\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mgather(\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;241m*\u001B[39m[\n\u001B[0;32m    715\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agenerate_with_cache(\n\u001B[0;32m    716\u001B[0m             m,\n\u001B[0;32m    717\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    718\u001B[0m             run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    719\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    720\u001B[0m         )\n\u001B[0;32m    721\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages)\n\u001B[0;32m    722\u001B[0m     ],\n\u001B[0;32m    723\u001B[0m     return_exceptions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    724\u001B[0m )\n\u001B[0;32m    725\u001B[0m exceptions \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mCancelledError\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m      3\u001B[0m         HumanMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m参考西游记唐僧的说话风格，写一篇奉劝年轻人努力工作的文章\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m     ],\n\u001B[0;32m      5\u001B[0m }\n\u001B[0;32m      7\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m}}\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mastream(inputs, config):\n\u001B[0;32m     10\u001B[0m     pretty_print_event_markdown(event)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langgraph\\pregel\\__init__.py:1874\u001B[0m, in \u001B[0;36mPregel.astream\u001B[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[0m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001B[39;00m\n\u001B[0;32m   1870\u001B[0m \u001B[38;5;66;03m# channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[0;32m   1871\u001B[0m \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[0;32m   1872\u001B[0m \u001B[38;5;66;03m# with channel updates applied only at the transition between steps\u001B[39;00m\n\u001B[0;32m   1873\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[1;32m-> 1874\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39matick(\n\u001B[0;32m   1875\u001B[0m         loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[0;32m   1876\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[0;32m   1877\u001B[0m         retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[0;32m   1878\u001B[0m         get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[0;32m   1879\u001B[0m     ):\n\u001B[0;32m   1880\u001B[0m         \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[0;32m   1881\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m output():\n\u001B[0;32m   1882\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m o\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langgraph\\pregel\\runner.py:362\u001B[0m, in \u001B[0;36mPregelRunner.atick\u001B[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[0;32m    360\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 362\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m arun_with_retry(\n\u001B[0;32m    363\u001B[0m         t,\n\u001B[0;32m    364\u001B[0m         retry_policy,\n\u001B[0;32m    365\u001B[0m         stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_astream,\n\u001B[0;32m    366\u001B[0m         configurable\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m    367\u001B[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001B[0;32m    368\u001B[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001B[0;32m    369\u001B[0m         },\n\u001B[0;32m    370\u001B[0m     )\n\u001B[0;32m    371\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langgraph\\pregel\\retry.py:132\u001B[0m, in \u001B[0;36marun_with_retry\u001B[1;34m(task, retry_policy, stream, configurable)\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m task\u001B[38;5;241m.\u001B[39mproc\u001B[38;5;241m.\u001B[39mainvoke(task\u001B[38;5;241m.\u001B[39minput, config)\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    134\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langgraph\\utils\\runnable.py:445\u001B[0m, in \u001B[0;36mRunnableSeq.ainvoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    441\u001B[0m config \u001B[38;5;241m=\u001B[39m patch_config(\n\u001B[0;32m    442\u001B[0m     config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    443\u001B[0m )\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 445\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m step\u001B[38;5;241m.\u001B[39mainvoke(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    446\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m step\u001B[38;5;241m.\u001B[39mainvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langgraph\\utils\\runnable.py:238\u001B[0m, in \u001B[0;36mRunnableCallable.ainvoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    236\u001B[0m         ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mcreate_task(coro, context\u001B[38;5;241m=\u001B[39mcontext)\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 238\u001B[0m         ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafunc(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse:\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m ret\u001B[38;5;241m.\u001B[39mainvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[1;32mIn[10], line 29\u001B[0m, in \u001B[0;36mreflection_node\u001B[1;34m(state)\u001B[0m\n\u001B[0;32m     24\u001B[0m translated \u001B[38;5;241m=\u001B[39m [state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;241m+\u001B[39m [\n\u001B[0;32m     25\u001B[0m     cls_map[msg\u001B[38;5;241m.\u001B[39mtype](content\u001B[38;5;241m=\u001B[39mmsg\u001B[38;5;241m.\u001B[39mcontent) \u001B[38;5;28;01mfor\u001B[39;00m msg \u001B[38;5;129;01min\u001B[39;00m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m     26\u001B[0m ]\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# 调用反思器(reflect)，将转换后的消息传入，获取反思结果\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m reflect\u001B[38;5;241m.\u001B[39mainvoke(translated)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# 返回新的状态，其中包含反思后的消息\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [HumanMessage(content\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mcontent)]}\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\runnables\\base.py:2923\u001B[0m, in \u001B[0;36mRunnableSequence.ainvoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m   2921\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mcreate_task(part(), context\u001B[38;5;241m=\u001B[39mcontext)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m   2922\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2923\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mcreate_task(part())\n\u001B[0;32m   2924\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[0;32m   2925\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mCancelledError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9e339-eb87-4707-a019-8387faaa52bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44173cab-4e51-4bd7-8c97-a28748e159a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f693e-441e-4536-8459-8042b34e4a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6092e5ee-7263-4f62-818a-0cc33ca0b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(content=\"参考西游记唐僧的说话风格，写一篇劝年轻人结婚买房的文章\")\n",
    "#     ],\n",
    "# }\n",
    "\n",
    "# config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# async for event in graph.astream(inputs, config):\n",
    "#     pretty_print_event_markdown(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e9c24-7cf7-42fa-be13-fbfebfdad5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a5187b-6b3b-4266-a226-f1e56e5ad350",
   "metadata": {},
   "source": [
    "## Homework: \n",
    "\n",
    "1. 扩展本指南的 Reflection Agent，使其能够完成更通用的生成任务，包括但不限于代码、报告等；\n",
    "2. 使用扩展后的 Reflection Agent 生成代码，实现在 GitHubSentinel 上新增一个信息渠道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b745d-ce5b-4a90-a3e8-64ecb3499c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affbb4d-f154-43e6-ae3d-d6a5dcd6e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9e0b07-62a8-430b-bf01-b7d8c07dd6e5",
   "metadata": {},
   "source": [
    "### 如何让 Reflection `System Prompt` 更加通用：\n",
    "\n",
    "如果你想让这个 `System Prompt` 适用于更广泛的内容评估场景，不局限于作文，你可以做一些轻微的调整。例如：\n",
    "\n",
    "```python\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a reviewer tasked with providing constructive critique and improvement suggestions for the user's submission.\"\n",
    "            \" Offer detailed feedback, including recommendations on clarity, structure, content depth, and style, as well as areas for improvement.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "### 修改后的变化：\n",
    "1. **角色定位更广泛**：从“老师”改为“审阅者”，这样不局限于评估作文，适用于各种类型的内容，包括文章、报告、甚至代码审查。\n",
    "  \n",
    "2. **批评与改进建议的灵活性**：从作文的“长度、深度、风格”拓展为“清晰度、结构、内容深度、风格”，这使得反馈更加多样化，适用于不同的内容类型。\n",
    "\n",
    "通过这种方式，可以让模型在更多场景下提供高质量的评估和反馈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b78d64-791c-484c-922d-d00a01b78a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
